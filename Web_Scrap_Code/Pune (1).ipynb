{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1i9DTAl8y0wt"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "counter = 1\n",
    "def writer(city_name , place_to_visit, place_name , reviews):\n",
    "    ''' This method is created to create output excel file with ease '''\n",
    "    global counter\n",
    "    \n",
    "    hotel_dict = {'city_name' : city_name , 'place_to_visit' : place_to_visit , 'place_name' : place_name , 'reviews' : reviews}\n",
    "    \n",
    "    df = pd.DataFrame(hotel_dict)\n",
    "    \n",
    "    folder_path = f'C:\\Major Project\\Web_Scapping\\\\{city_name}\\\\{place_to_visit}\\\\{counter}.xlsx'\n",
    "    \n",
    "    df.to_excel( folder_path , index = False , header = True)\n",
    "    \n",
    "    print('This files has',len(reviews),'rows')\n",
    "    \n",
    "    print(f'File : {counter}.xlsx  written to path' )\n",
    "    \n",
    "    counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDqaceGqy1lA",
    "outputId": "17d848fc-3ce2-4504-d331-be767615f005"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIr-JZlWOtpU"
   },
   "source": [
    "# **Hotels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SONgfALh03_t",
    "outputId": "ce499cad-95c5-4a4a-f51a-9216cd34258b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 1.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 2.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 3.xlsx  written to path\n",
      "This files has 290 rows\n",
      "File : 4.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 5.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"**Hotels**\n",
    "\n",
    "# **1.Conrad Pune**\n",
    "\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d8625588-Reviews'\n",
    "\n",
    "url_last = 'Conrad_Pune-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_ConradPune = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_ConradPune.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , 'Conrad Pune' , reviews_ConradPune)\n",
    "\n",
    "\"\"\"# 2.Hyatt Punet\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d1866256-Reviews'\n",
    "\n",
    "url_last = 'Hyatt_Pune-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "\n",
    "reviews_HyattPune= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_HyattPune.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , 'Hyatt Pune' , reviews_HyattPune)\n",
    "\n",
    "\"\"\"# **3.iJW Marriott Hotel Pune*\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d1859177-Reviews'\n",
    "\n",
    "url_last = 'JW_Marriott_Hotel_Pune-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "\n",
    "reviews_jw= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_jw.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , 'JW Marriott Hotel Pune' , reviews_jw)\n",
    "\n",
    "\"\"\"# 4.The Central Park Hotel\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d1170606-Reviews'\n",
    "\n",
    "url_last = 'The_Central_Park_Hotel-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "\n",
    "reviews_cen= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_cen.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , 'The Central Park Hotel' , reviews_cen)\n",
    "\n",
    "\"\"\"## **5.The Orchid Hotel**\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d2304344-Reviews'\n",
    "\n",
    "url_last = 'The_Orchid_Hotel-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "\n",
    "reviews_orchid= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_orchid.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , 'The Orchid Hotel' , reviews_orchid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. The Corinthians Resort & Club\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d619336-Reviews'\n",
    "\n",
    "url_last = 'The_Corinthians_Resort_Club-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_corn = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_corn.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 6.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , 'The Corinthians Resort & Club' , reviews_corn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Lemon Tree Premier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d15527910-Reviews'\n",
    "\n",
    "url_last = 'Lemon_Tree_Premier_City_Center_Pune-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_lemon = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_lemon.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 7.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , 'Lemon Tree Premier' , reviews_lemon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.  Four Points By Sheraton Hotel & Serviced Apartments, Pune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d2037993-Reviews'\n",
    "\n",
    "url_last = 'Four_Points_By_Sheraton_Hotel_Serviced_Apartments_Pune-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_four = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_four.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 8.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , ' Four Points By Sheraton Hotel & Serviced Apartments' , reviews_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. St Laurn Koregaon Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d1043544-Reviews'\n",
    "\n",
    "url_last = 'St_Laurn_Koregaon_Park-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_st = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_st.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 9.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , 'St Laurn Koregaon Park' , reviews_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Hotel Parc Estique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297654-d1563533-Reviews'\n",
    "\n",
    "url_last = 'Hotel_Parc_Estique-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_parc = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_parc.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 10.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "#print(reviews_pullman)\n",
    "writer('Pune' , 'Hotels' , 'Hotel Parc Estique' , reviews_parc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVcaVT2sO-lo"
   },
   "source": [
    "# **Restaurants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eODvmUqS1B2c",
    "outputId": "87895d16-4eb9-4659-b321-00eead6b3360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 11.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 12.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 13.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 14.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 15.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"# **TOP 5 Restaurants**\n",
    "\n",
    "1.Vaishali Restaurant\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d801879-Reviews'\n",
    "\n",
    "url_last = 'Vaishali_Restaurant-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_vaishali = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_vaishali.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune' , 'Restaurant' , 'Vaishali Restaurant' , reviews_vaishali)\n",
    "\n",
    "\"\"\"## **2.Cafe GoodLuck**\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d799471-Reviews'\n",
    "\n",
    "url_last = 'Cafe_GoodLuck-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_cafe = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_cafe.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune', 'Restaurant' , 'Cafe GoodLuck' , reviews_cafe)\n",
    "\n",
    "\"\"\"# **3.Malaka Spice**\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d808529-Reviews'\n",
    "\n",
    "url_last = 'Malaka_Spice-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_malaka = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_malaka.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune' , 'Restaurant' , 'Malaka Spice' , reviews_malaka)\n",
    "\n",
    "\"\"\"## **4.Blue Nile**\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d1075367-Reviews'\n",
    "\n",
    "url_last = 'Blue_Nile-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_Blue= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_Blue.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune' , 'Restaurant' , 'Blue Nile' , reviews_Blue)\n",
    "\n",
    "\"\"\"## **5.JJ Garden Vada Pav**\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d1769051-Reviews'\n",
    "\n",
    "url_last = 'JJ_Garden_Vada_Pav-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_jj= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_jj.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune' , 'Restaurant' , 'JJ Garden Vada Pav' , reviews_jj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Paasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d2334912-Reviews'\n",
    "\n",
    "url_last = 'Paasha-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_paa = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_paa.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 16.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Pune' , 'Restaurant' , 'Paasha' , reviews_paa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Spice Kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d2076261-Reviews'\n",
    "\n",
    "url_last = 'Spice_Kitchen-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_spice = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_spice.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 17.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Pune' , 'Restaurant' , 'Spice Kitchen' , reviews_spice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d12658537-Reviews'\n",
    "\n",
    "url_last = 'Mosaic-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_mos = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_mos.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 18.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Pune' , 'Restaurant' , 'Mosaic' , reviews_mos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Chingari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d2194941-Reviews'\n",
    "\n",
    "url_last = 'Chingari-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_chi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_chi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 19.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Pune' , 'Restaurant' , 'Chingari' , reviews_chi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Wadeshwar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297654-d1094340-Reviews'\n",
    "\n",
    "url_last = 'Wadeshwar-Pune_Pune_District_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_wad = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_wad.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 20.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Pune' , 'Restaurant' , 'Wadeshwar' , reviews_wad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJXuka7ePM9u"
   },
   "source": [
    "# **Things To Do**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGl1XfSP1HsD",
    "outputId": "1ab0ba32-20d4-41db-8c32-7a2a510783d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 21.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 22.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 23.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 24.xlsx  written to path\n",
      "This files has 300 rows\n",
      "File : 25.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# **Things To DO**\n",
    "\n",
    "1.Shaniwar Wada\n",
    "\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297654-d321429-Reviews'\n",
    "\n",
    "url_last = 'Shaniwar_Wada-Pune_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_Shaniwar= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_Shaniwar.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune' , 'Things' , 'Shaniwar Wada' , reviews_Shaniwar)\n",
    "\n",
    "\"\"\"2.Laxmi Road\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297654-d320051-Reviews'\n",
    "\n",
    "url_last = 'Laxmi_Road-Pune_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_laxmi= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_laxmi.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune' , 'Things' , 'Laxmi Road' , reviews_laxmi)\n",
    "\n",
    "\"\"\"3.Bhimashankar Temple\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g2287403-d1204285-Reviews'\n",
    "\n",
    "url_last = 'Bhimashankar_Temple-Bhimashankar_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_temple= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_temple.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune' , 'Things' , 'Bhimashankar Temple' , reviews_temple)\n",
    "\n",
    "\"\"\"4. Sinhagad Fort\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297654-d2408845-Reviews'\n",
    "\n",
    "url_last = 'Sinhagad_Fort-Pune_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_fort= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_fort.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune' , 'Things' , 'Sinhagad Fort' , reviews_fort)\n",
    "\n",
    "\"\"\"Dagadusheth Halwai Ganapati Temple\"\"\"\n",
    "\n",
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297654-d2520937-Reviews'\n",
    "\n",
    "url_last = 'Dagadusheth_Halwai_Ganapati_Temple-Pune_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_Ganpati= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_Ganpati.append(review_text.text)\n",
    "#%%\n",
    "writer('Pune' , 'Things' , 'Dagadusheth Halwai Ganapati Temple' , reviews_Ganpati)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Darshan Museum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297654-d2312973-Reviews'\n",
    "\n",
    "url_last = 'Darshan_Museum-Pune_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_dar = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_dar.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 26.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Pune' , 'Things' , 'Darshan Museum' , reviews_dar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Phoenix Market City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297654-d2486481-Reviews'\n",
    "\n",
    "url_last = 'Phoenix_Market_City-Pune_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_ph = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_ph.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 27.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Pune' , 'Things' , 'Phoenix Market City' , reviews_ph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Pune-Okayama Friendship Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297654-d2692076-Reviews'\n",
    "\n",
    "url_last = 'Pune_Okayama_Friendship_Garden-Pune_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_okay = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_okay.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 28.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Pune' , 'Things' , 'Pune-Okayama Friendship Garden' , reviews_okay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Raja Dinkar Kelkar Museum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297654-d320029-Reviews'\n",
    "\n",
    "url_last = 'Raja_Dinkar_Kelkar_Museum-Pune_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_raja = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_raja.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 29.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Pune' , 'Things' , 'Raja Dinkar Kelkar Museum' , reviews_raja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Aga Khan Palace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297654-d2178321-Reviews'\n",
    "\n",
    "url_last = 'Aga_Khan_Palace-Pune_Pune_District_Maharashtra.html'\n",
    "    \n",
    "reviews_aga = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_aga.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer('Pune' , 'Things' , 'Aga Khan Palace' , reviews_aga)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

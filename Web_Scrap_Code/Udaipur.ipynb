{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "77mrHFeya365"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.The_Leela_Palace**"
      ],
      "metadata": {
        "id": "5D6B0pz9b9Sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 1\n",
        "def writer(city_name , place_to_visit, place_name , reviews):\n",
        "    ''' This method is created to create output excel file with ease '''\n",
        "    global counter\n",
        "    \n",
        "    hotel_dict = {'city_name' : city_name , 'place_to_visit' : place_to_visit , 'place_name' : place_name , 'reviews' : reviews}\n",
        "    \n",
        "    df = pd.DataFrame(hotel_dict)\n",
        "    \n",
        "    folder_path = f'C:\\\\Users\\\\Desktop\\\\Web_scrapping\\\\{city_name}\\\\{place_to_visit}\\\\{counter}.xlsx'\n",
        "    \n",
        "    df.to_excel( folder_path , index = False , header = True)\n",
        "    \n",
        "    print('This files has',len(reviews),'rows')\n",
        "    \n",
        "    print(f'File : {counter}.xlsx  written to path' )\n",
        "    \n",
        "    counter = counter + 1"
      ],
      "metadata": {
        "id": "2FiRnAiobBRy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297672-d1440338-Reviews'\n",
        "\n",
        "url_last = 'The_Leela_Palace_Udaipur-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_The_Leela_Palace = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_The_Leela_Palace.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_Leela_Palace)\n"
      ],
      "metadata": {
        "id": "z1iTeBRDbBVP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'The_Leela_Palace' , reviews_The_Leela_Palace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_i8miPabBX0",
        "outputId": "ba440b66-b29e-4d43-b5ca-b273fb2a2254"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 1.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.**TatSaraasa_Resort**"
      ],
      "metadata": {
        "id": "x_mGG_XLcG_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297672-d7272036-Reviews'\n",
        "\n",
        "url_last = 'TatSaraasa_Resort_Spa-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_TatSaraasa_Resort = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_TatSaraasa_Resort.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_TatSaraasa_Resort)\n"
      ],
      "metadata": {
        "id": "q9zfNn9wcIi6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'TatSaraasa_Resort' , reviews_TatSaraasa_Resort)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzTgFKyycImH",
        "outputId": "a0034eda-b106-4c61-8123-6e01c45997a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 2.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.Club_Mahindra**"
      ],
      "metadata": {
        "id": "6afMNQtMcwEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297672-d2407028-Reviews'\n",
        "\n",
        "url_last = 'Club_Mahindra_Udaipur-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_Club_Mahindra = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Club_Mahindra.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_Club_Mahindra)\n"
      ],
      "metadata": {
        "id": "BMz2yDracIos"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'TatSaraasa_Resort' , reviews_TatSaraasa_Resort)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHUeoPyVcIrT",
        "outputId": "b6b6a5c2-3b2b-40d4-d4b5-d8e11a1a17a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 3.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.**The_Lalit_Laxmi_Vilas_Palace**"
      ],
      "metadata": {
        "id": "PUQt5gyUcx88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297672-d530387-Reviews'\n",
        "\n",
        "url_last = 'The_Lalit_Laxmi_Vilas_Palace_Udaipur-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_The_Lalit_Laxmi_Vilas_Palace = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_The_Lalit_Laxmi_Vilas_Palace.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_Lalit_Laxmi_Vilas_Palace)\n"
      ],
      "metadata": {
        "id": "0pZlzvOhcIt_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'The_Lalit_Laxmi_Vilas_Palace' , reviews_The_Lalit_Laxmi_Vilas_Palace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qmej84_cIxR",
        "outputId": "50117750-aac9-4c01-b8f5-c451d11cd977"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 4.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.The Ananta Udaipur**"
      ],
      "metadata": {
        "id": "kSxHT3Tyczys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g17209644-d6562572-Reviews'\n",
        "\n",
        "url_last = 'The_Ananta_Udaipur-Bhujra_Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_The_Ananta_Udaipur = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_The_Ananta_Udaipur.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_Ananta_Udaipur)\n"
      ],
      "metadata": {
        "id": "9Tw8Q-nycI00"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'The_Ananta_Udaipur' , reviews_The_Ananta_Udaipur)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebsun7rrcI3i",
        "outputId": "9af4ed44-b987-4452-a975-b613a94f1826"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 5.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.**Ramada**"
      ],
      "metadata": {
        "id": "iYI6guRSc2kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297672-d1776501-Reviews'\n",
        "\n",
        "url_last = 'Ramada_by_Wyndham_Udaipur_Resort_and_Spa-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_Ramada = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Ramada.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_Ramada)\n"
      ],
      "metadata": {
        "id": "SbL0RPucbBa0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'The_Ramada' , reviews_Ramada)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SM5tQoNbBd5",
        "outputId": "6cd8d839-9be2-4020-be13-cca730df7b7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 6.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.**Bamboo_Saa_Resort**"
      ],
      "metadata": {
        "id": "4TmtJfF8c3zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297672-d13323739-Reviews'\n",
        "\n",
        "url_last = 'Bamboo_Saa_Resort_Spa-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_Bamboo_Saa_Resort = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Bamboo_Saa_Resort.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_Bamboo_Saa_Resort)\n"
      ],
      "metadata": {
        "id": "mKfZst-hbB-4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'Bamboo_Saa_Resort' , reviews_Bamboo_Saa_Resort)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMsKMFeFcksr",
        "outputId": "6c6fee16-9d44-4249-c154-9b6d735b0b9d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 7.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.**Radisson**"
      ],
      "metadata": {
        "id": "8jFS8VCcc5Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297672-d1853086-Reviews'\n",
        "\n",
        "url_last = 'Radisson_Blu_Udaipur_Palace_Resort_Spa-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_Radisson = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Radisson.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_Radisson)\n"
      ],
      "metadata": {
        "id": "xLhcAxLQckwH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'Radissonr' , reviews_Radisson)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ms-QkMlckzg",
        "outputId": "8b7007d9-b044-475e-e813-d9ccf291e5b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 8.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.**JuSTa_Rajputana**"
      ],
      "metadata": {
        "id": "r-Qf2gdcc6PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297672-d735414-Reviews'\n",
        "\n",
        "url_last = 'JuSTa_Rajputana_Udaipur_Resort-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_JuSTa_Rajputana = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_JuSTa_Rajputana.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_JuSTa_Rajputana)\n"
      ],
      "metadata": {
        "id": "RFtbpcUVck2i"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'JuSTa_Rajputana' , reviews_JuSTa_Rajputana)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujh9Ud6Mck6A",
        "outputId": "ac15ed6d-b64e-417e-8c30-5eb87e4f0dcb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 11.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.**The_Oberoi_Udaivilas**"
      ],
      "metadata": {
        "id": "0f50LACZc7Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297672-d302891-Reviews'\n",
        "\n",
        "url_last = 'The_Oberoi_Udaivilas_Udaipur-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "\n",
        "reviews_The_Oberoi_Udaivilas= []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_The_Oberoi_Udaivilas.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_Oberoi_Udaivilas)\n"
      ],
      "metadata": {
        "id": "xnqu1LUyck8z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Hotels' , 'The_Oberoi_Udaivilas' , reviews_The_Oberoi_Udaivilas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84pN17V7clAM",
        "outputId": "370e37cd-52d8-413b-ae8e-58ca76040450"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 10.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Restaurants**"
      ],
      "metadata": {
        "id": "k6qCVRWYqCF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Jaiwana **Haveli**"
      ],
      "metadata": {
        "id": "GxcfgDOrqIH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d1594057-Reviews'\n",
        "\n",
        "url_last = 'Jaiwana_Haveli_Roof_Top_Restaurant-Udaipur_Udaipur_District_Rajasthan.htmll'\n",
        "\n",
        "reviews_Jaiwana_Haveli = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Jaiwana_Haveli.append(review_text.text)"
      ],
      "metadata": {
        "id": "Gvq8oEUYbCCA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Jaiwana_Haveli' , reviews_Jaiwana_Haveli)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht0AVsY3qUso",
        "outputId": "544eb65a-b7e7-45dc-b8d1-f46e71984fd8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 12.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.**Raas_Leela**"
      ],
      "metadata": {
        "id": "H9lg2G0xsdpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d3381984-Reviews'\n",
        "\n",
        "url_last = 'Raas_Leela-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "reviews_Raas_Leela = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Raas_Leela.append(review_text.text)"
      ],
      "metadata": {
        "id": "_ogaiZO0qU4s"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Raas_Leela' , reviews_Raas_Leela)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNFl0i-8sZN8",
        "outputId": "6260f45e-3425-4f88-b027-e58570b0c3a4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 299 rows\n",
            "File : 13.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.Restaurant **Harigarh**"
      ],
      "metadata": {
        "id": "3O-hwAgCsfPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d7211240-Reviews'\n",
        "\n",
        "url_last = 'Restaurant_Harigarh-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "reviews_Restaurant_Harigarh = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Restaurant_Harigarh.append(review_text.text)"
      ],
      "metadata": {
        "id": "iElPGDj2sZdf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Restaurant_Harigarh' , reviews_Restaurant_Harigarh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEjLkFFVsZgr",
        "outputId": "cc313e5f-a992-4d75-d28d-57e575bd3f82"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 14.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.**Khamma_Ghani_Restaurant**"
      ],
      "metadata": {
        "id": "6SjRZeujsf5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d12069003-Reviews'\n",
        "\n",
        "url_last = 'Khamma_Ghani_Restaurant-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "reviews_Khamma_Ghani_Restaurant = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Khamma_Ghani_Restaurant.append(review_text.text)"
      ],
      "metadata": {
        "id": "r4kj-v3qsZlS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Khamma_Ghani_Restaurant' , reviews_Khamma_Ghani_Restaurant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEClqhXBsZpL",
        "outputId": "d22b4291-31b3-476d-ede2-5c1d057f3f83"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 15.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.Ambrai_Restaurant"
      ],
      "metadata": {
        "id": "366ZzcbqshQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d1202129-Reviews'\n",
        "\n",
        "url_last = 'Ambrai_Restaurant-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "reviews_Ambrai_Restaurant = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Ambrai_Restaurant.append(review_text.text)"
      ],
      "metadata": {
        "id": "loUgJJsLsZub"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Ambrai_Restaurant' , reviews_Ambrai_Restaurant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2owP6so_saC9",
        "outputId": "58c271b4-e18b-4797-c841-0b4e56c7b7a2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 17.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.**Upre**"
      ],
      "metadata": {
        "id": "_3ahKi7TsiDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d1960600-Reviews'\n",
        "\n",
        "url_last = 'Upre-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "reviews_Upre = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Upre.append(review_text.text)"
      ],
      "metadata": {
        "id": "ngS2Q6lbsaIk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Upre' , reviews_Upre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wQD5vFjsaMa",
        "outputId": "9fe464f7-6539-4277-c0e5-47f99be76244"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 18.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sunset_Terrace**"
      ],
      "metadata": {
        "id": "3xV2elztsi6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d1645593-Reviews'\n",
        "\n",
        "url_last = 'Sunset_Terrace-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "reviews_Sunset_Terrace = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Sunset_Terrace.append(review_text.text)"
      ],
      "metadata": {
        "id": "REWfKPn4sadR"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Sunset_Terrace' , reviews_Sunset_Terrace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UMUISclqU8Y",
        "outputId": "008f898d-c018-4512-8b80-3a7cd75169fa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 19.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.**Myra**"
      ],
      "metadata": {
        "id": "8Bf0RBYHsjkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d7089635-Reviews'\n",
        "\n",
        "url_last = 'Myra_by_Ramada_Udaipur_Resort_Spa-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "reviews_Myra = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Myra.append(review_text.text)"
      ],
      "metadata": {
        "id": "WXKQ96W6qVAA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Myra' , reviews_Myra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TgClOT4qVDF",
        "outputId": "ff4883d1-9081-4fea-9fcb-7261dd01adea"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 20.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.**Neelam_Restaurant**"
      ],
      "metadata": {
        "id": "6HNk4iSSskLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d10021952-Reviews'\n",
        "\n",
        "url_last = 'Neelam_Restaurant-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "reviews_Neelam_Restaurant = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Neelam_Restaurant.append(review_text.text)"
      ],
      "metadata": {
        "id": "0b15dmqxskmO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Neelam_Restaurant' , reviews_Neelam_Restaurant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfSah0erskrJ",
        "outputId": "52e3c8e5-826e-450f-d71d-e38cf3c9af4c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 21.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.**Jagat_Niwas**"
      ],
      "metadata": {
        "id": "J5gro29TsyHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297672-d1178117-Reviews'\n",
        "\n",
        "url_last = 'Jagat_Niwas_Palace-Udaipur_Udaipur_District_Rajasthan.html'\n",
        "\n",
        "reviews_Jagat_Niwas = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Jagat_Niwas.append(review_text.text)"
      ],
      "metadata": {
        "id": "I_auu-bjskuH"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Udaipur' , 'Restaurant' , 'Jagat_Niwas' , reviews_Jagat_Niwas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bvc1gA4skxX",
        "outputId": "ef9cc9f1-47f1-4fc9-a398-20a856495ee0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 22.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Things to do**"
      ],
      "metadata": {
        "id": "m3ODkka-2k5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1."
      ],
      "metadata": {
        "id": "FgaDn6Nx5A0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zwej46zg2kFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2rRUwvosk1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2."
      ],
      "metadata": {
        "id": "D_KWZMGi3-6g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KSWh9YJ54I6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n3YtFL7V2GQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3."
      ],
      "metadata": {
        "id": "wYfrZMcu3_iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nyq-AYR32GT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNMj64oN4NST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4."
      ],
      "metadata": {
        "id": "a2pf14Mt4ART"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWgWYRHr2GX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Bxb92ib2GdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5."
      ],
      "metadata": {
        "id": "8blS5cK34BBC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UxBydXSp2Gjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YA5sqetbqVGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6."
      ],
      "metadata": {
        "id": "X69fOmuU4S8F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpcadJDW4RHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CD-LBSB74RLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7."
      ],
      "metadata": {
        "id": "udb-JCDm4U7S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbV39xQ84RQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVwGaS4P4RUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8."
      ],
      "metadata": {
        "id": "M6DLqKBm4V2H"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B0LK7k_I4RYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-cFyxbIi4Rby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9."
      ],
      "metadata": {
        "id": "3VnH_bPa4Wz7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQmNF-4q4Rsz"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sfA9viiI4Rwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10."
      ],
      "metadata": {
        "id": "KCwb0fe_4Yoq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3HuIupfX4XpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNX1pBKu4YAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
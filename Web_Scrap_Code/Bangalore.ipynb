{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5dce4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12ad235",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "def writer(city_name , place_to_visit, place_name , reviews):\n",
    "    ''' This method is created to create output excel file with ease '''\n",
    "    global counter\n",
    "    \n",
    "    hotel_dict = {'city_name' : city_name , 'place_to_visit' : place_to_visit , 'place_name' : place_name , 'reviews' : reviews}\n",
    "    \n",
    "    df = pd.DataFrame(hotel_dict)\n",
    "    \n",
    "    folder_path = f'C:\\Major Project\\Web_Scapping\\\\{city_name}\\\\{place_to_visit}\\\\{counter}.xlsx'\n",
    "    \n",
    "    df.to_excel( folder_path , index = False , header = True)\n",
    "    \n",
    "    print('This files has',len(reviews),'rows')\n",
    "    \n",
    "    print(f'File : {counter}.xlsx  written to path' )\n",
    "    \n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a50d5c",
   "metadata": {},
   "source": [
    "## Hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0231596f",
   "metadata": {},
   "source": [
    "1. Sheraton Grand Bengaluru Whitefield Hotel & Convention Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe50d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d13943346-Reviews'\n",
    "\n",
    "url_last = 'Sheraton_Grand_Bengaluru_Whitefield_Hotel_Convention_Center-Bengaluru_Bangalore_Distr.html'\n",
    "\n",
    "\n",
    "reviews_sheraton = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sheraton.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4caacb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 1.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'Sheraton Grand Bengaluru Whitefield Hotel & Convention Center' , reviews_sheraton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de831b13",
   "metadata": {},
   "source": [
    "2. Clarks Exotica Convention Resort & Spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c98b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d1155585-Reviews'\n",
    "\n",
    "url_last = 'Clarks_Exotica_Convention_Resort_Spa-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_clarks = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_clarks.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bdf90fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 2.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'Clarks Exotica Convention Resort & Spa' , reviews_clarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe9393",
   "metadata": {},
   "source": [
    "3. Royal Orchid Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "491f11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d503249-Reviews'\n",
    "\n",
    "url_last = 'Royal_Orchid_Central-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_royal = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_royal.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20acae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 3.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'Royal Orchid Central' , reviews_royal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ada84d",
   "metadata": {},
   "source": [
    "4. Svenska Design Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "992654b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d1797807-Reviews'\n",
    "\n",
    "url_last = 'Svenska_Design_Hotel-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_svenska = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_svenska.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99716e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 4.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'Svenska Design Hotel' , reviews_svenska)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb14ebee",
   "metadata": {},
   "source": [
    "5. Palm Meadows Resort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00c1fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d602617-Reviews'\n",
    "\n",
    "url_last = 'Palm_Meadows_Resort-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_palm = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_palm.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b74cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 5.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'Palm Meadows Resort' , reviews_palm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed62152f",
   "metadata": {},
   "source": [
    "6. Davanam Sarovar Portico Suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b1c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d3365457-Reviews'\n",
    "\n",
    "url_last = 'Davanam_Sarovar_Portico_Suites-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_davanam = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_davanam.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "008fea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 6.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'Davanam Sarovar Portico Suites' , reviews_davanam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d9f4cc",
   "metadata": {},
   "source": [
    "7. Sarovar Portico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3d85ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d10847336-Reviews'\n",
    "\n",
    "url_last = 'Sarovar_Portico_Outer_Ring_Road_Bengaluru-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_sarovar = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sarovar.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ff972e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 7.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'Sarovar Portico' , reviews_sarovar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf86de0",
   "metadata": {},
   "source": [
    "8. Angsana Oasis Spa & Resort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54a61ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d471974-Reviews'\n",
    "\n",
    "url_last = 'Angsana_Oasis_Spa_Resort-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_angasana = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_angasana.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ed1b8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 8.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'Angsana Oasis Spa & Resort' , reviews_angasana)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd84e44",
   "metadata": {},
   "source": [
    "9. The Chancery Pavilion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5c5a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d596442-Reviews'\n",
    "\n",
    "url_last = 'The_Chancery_Pavilion-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_chancery = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_chancery.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f620ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 9.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'The Chancery Pavilion' , reviews_chancery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59207f71",
   "metadata": {},
   "source": [
    "10. The Park Bangalore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0761d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297628-d301635-Reviews'\n",
    "\n",
    "url_last = 'The_Park_Bangalore-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_park = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_park.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe388fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 10.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Hotels' , 'The Park Bangalore' , reviews_park)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e400a",
   "metadata": {},
   "source": [
    "## Restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80adad28",
   "metadata": {},
   "source": [
    "1. Byg Brewski Brewing Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab580385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d7178495-Reviews'\n",
    "\n",
    "url_last = 'Byg_Brewski_Brewing_Company-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_byg = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_byg.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "222c0b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 11.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'Byg Brewski Brewing Company' , reviews_byg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc796e",
   "metadata": {},
   "source": [
    "2.  One Atria Cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b6e151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d13356884-Reviews'\n",
    "\n",
    "url_last = 'One_Atria_Cafe-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_one= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_one.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57d69ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 12.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'One Atria Cafe' , reviews_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171b3a1",
   "metadata": {},
   "source": [
    "3. Lush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f1f4017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d14796026-Reviews'\n",
    "\n",
    "url_last = 'Lush-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_lush= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_lush.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0b95af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 13.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'Lush' , reviews_lush)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e66771",
   "metadata": {},
   "source": [
    "4. The Royal Afghan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "353d9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d1066850-Reviews'\n",
    "\n",
    "url_last = 'The_Royal_Afghan-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_royal= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_royal.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83f75d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 14.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'Royal' , reviews_royal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0687435c",
   "metadata": {},
   "source": [
    "5. M Cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28eed22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d4641668-Reviews'\n",
    "\n",
    "url_last = 'M_Cafe-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_m= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_m.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a2b5986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 15.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'M Cafe' , reviews_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a8441",
   "metadata": {},
   "source": [
    "6. Time Traveller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d11f58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d1389538-Reviews'\n",
    "\n",
    "url_last = 'Time_Traveller-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_time= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_ = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_time.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5ddf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 16.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'Time Traveller' , reviews_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2340964",
   "metadata": {},
   "source": [
    "7. The Druid Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a978f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d11860902-Reviews'\n",
    "\n",
    "url_last = 'The_Druid_Garden-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_druid= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_ = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_druid.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32db8f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 17.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'The Druid Garden' , reviews_druid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ad6ff",
   "metadata": {},
   "source": [
    "8. The Fatty Bao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40fdf2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d6942844-Reviews'\n",
    "\n",
    "url_last = 'The_Fatty_Bao-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_fatty= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_ = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_fatty.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe584b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 18.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'The Fatty Bao' , reviews_fatty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a7def8",
   "metadata": {},
   "source": [
    "9. Nagarjuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1381ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d1060248-Reviews'\n",
    "\n",
    "url_last = 'Nagarjuna-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_nagarjuna= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_ = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_nagarjuna.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a37262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 19.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'Nagarjuna' , reviews_nagarjuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18a188",
   "metadata": {},
   "source": [
    "10. Rajdhani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8affc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297628-d3427289-Reviews'\n",
    "\n",
    "url_last = 'Rajdhani-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "\n",
    "\n",
    "reviews_Rajdhani= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_ = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "   # tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    #for t in tags_to_delete:\n",
    "        #t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           # review_text.span.decompose()\n",
    "            reviews_Rajdhani.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9a57c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 20.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Restaurants' , 'Rajdhani' , reviews_Rajdhani)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28b36d4",
   "metadata": {},
   "source": [
    "## Things"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e33a64",
   "metadata": {},
   "source": [
    "1. ISKCON Temple Bangalore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d524ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d325162-Reviews'\n",
    "\n",
    "url_last = 'ISKCON_Temple_Bangalore-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "    \n",
    "reviews_iskcon = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_iskcon.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdcc82c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 21.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , 'Iskcon Temple' , reviews_iskcon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e33675",
   "metadata": {},
   "source": [
    "2. UB City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b42ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d3807223-Reviews'\n",
    "\n",
    "url_last = 'UB_City-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "    \n",
    "reviews_ub = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_ub.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9429bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 22.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , 'UB City' , reviews_ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14488356",
   "metadata": {},
   "source": [
    "3. Bannerghatta national park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58c24d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d1006969-Reviews'\n",
    "\n",
    "url_last = 'Bannerghatta_National_Park-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "    \n",
    "reviews_bannerghatta = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_bannerghatta.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "853dfd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 23.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , 'Bannerghatta national park' , reviews_bannerghatta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb502782",
   "metadata": {},
   "source": [
    "4. Wonderla amusement park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d4c97ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d1603947-Reviews'\n",
    "\n",
    "url_last = 'Wonderla_Amusement_Park-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "    \n",
    "reviews_wonderela = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_wonderela.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ec6c87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 24.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , 'Wonderla amusement park' , reviews_wonderela)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e46f7f",
   "metadata": {},
   "source": [
    "5. Visvesvaraya Industrial and Technological Museum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21d7b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d2587719-Reviews'\n",
    "\n",
    "url_last = 'Visvesvaraya_Industrial_and_Technological_Museum-Bengaluru_Bangalore_District_Kar.html'\n",
    "    \n",
    "reviews_vitm = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_vitm.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20d14f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 25.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , 'Visvesvaraya Industrial and Technological Museum' , reviews_vitm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454de1f4",
   "metadata": {},
   "source": [
    "6.  Lalbagh Botanical Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53b45e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d631367-Reviews'\n",
    "\n",
    "url_last = 'Lalbagh_Botanical_Garden-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "    \n",
    "reviews_lalbagh = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_lalbagh.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18c369bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 26.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , ' Lalbagh Botanical Garden' , reviews_lalbagh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e11a6",
   "metadata": {},
   "source": [
    "7. Cubbon Park "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8a5f45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d2587630-Reviews'\n",
    "\n",
    "url_last = 'Cubbon_Park-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "    \n",
    "reviews_cubbon = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_cubbon.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2027ffa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 27.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , 'Cubbon Park' , reviews_cubbon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b780593",
   "metadata": {},
   "source": [
    "8. Bangalore Palace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92f86e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d2069428-Reviews'\n",
    "\n",
    "url_last = 'Bangalore_Palace-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "    \n",
    "reviews_palace = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_palace.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66d32c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 28.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , 'Bangalore Palace' , reviews_palace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93122e2",
   "metadata": {},
   "source": [
    "9. Orion Mall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "725f6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d3840218-Reviews'\n",
    "\n",
    "url_last = 'Orion_Mall-Bengaluru_Bangalore_District_Karnataka.html'\n",
    "    \n",
    "reviews_orion = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_orion.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8cf20e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 29.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , 'Orion Mall' , reviews_orion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b699eb",
   "metadata": {},
   "source": [
    "10. Ragigudda Sri Prasanna Anjaneyaswamy Temple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "663f3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297628-d4401144-Reviews'\n",
    "\n",
    "url_last = 'Ragigudda_Sri_Prasanna_Anjaneyaswamy_Temple-Bengaluru_Bangalore_District_Karnatak.html'\n",
    "    \n",
    "reviews_ragi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_ragi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b64eaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 30.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Bangalore' , 'Things' , 'Ragigudda Sri Prasanna Anjaneyaswamy Temple' , reviews_ragi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b522539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

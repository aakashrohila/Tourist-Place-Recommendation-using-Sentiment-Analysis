{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c8e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd2e5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "def writer(city_name, place_to_visit, place_name, reviews):\n",
    "    ''' This method is created to create output excel file with ease '''\n",
    "    global counter\n",
    "    \n",
    "    hotel_dict = {'city_name':city_name, 'place_to_visit': place_to_visit, 'place_name': place_name, 'reviews': reviews}\n",
    "    \n",
    "    df=pd.DataFrame(hotel_dict)\n",
    "    folder_path = f'C:\\Modules\\Major Project\\Web_Scrapping\\\\{city_name}\\\\{place_to_visit}\\\\{counter}.xlsx'\n",
    "    \n",
    "    df.to_excel(folder_path, index=False, header=True)\n",
    "    \n",
    "    print('This files has',len(reviews),'rows')\n",
    "    \n",
    "    print(f'File : {counter}.xlsx written to path')\n",
    "    \n",
    "    counter = counter+1\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2f94f",
   "metadata": {},
   "source": [
    "# JAIPUR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df618c56",
   "metadata": {},
   "source": [
    "# Hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dc580",
   "metadata": {},
   "source": [
    "## 1. Fairmont Jaipur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67fb9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g2555901-d2446448-Reviews'\n",
    "\n",
    "url_last = 'Fairmont_Jaipur-Kookas_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_fair = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_fair.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_fair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4027c297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 1.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','Fairmont Jaipur', reviews_fair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c21ed4",
   "metadata": {},
   "source": [
    "## 2. Hotel Anuraag Villa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c60e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304555-d568124-Reviews'\n",
    "\n",
    "url_last = 'Hotel_Anuraag_Villa-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_anu = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_anu.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_anu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95dd9494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 2.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','Hotel Anuraag Villa', reviews_anu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80f4e9",
   "metadata": {},
   "source": [
    "## 3. Lemon Tree Premier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ea9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304555-d844647-Reviews'\n",
    "\n",
    "url_last = 'Lemon_Tree_Premier_Jaipur-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_lemon = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_lemon.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lemon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "917218dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 3.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','Lemon Tree Premier', reviews_lemon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c2f03",
   "metadata": {},
   "source": [
    "## 4. Red Fox Hotel, Jaipur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f633c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304555-d1626357-Reviews'\n",
    "\n",
    "url_last = 'Red_Fox_Hotel_Jaipur-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_red = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_red.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_red)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "615b770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 4.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','Red Fox Hotel, Jaipur', reviews_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0e50f",
   "metadata": {},
   "source": [
    "## 5. The Fern - An Ecotel Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00009df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304555-d1558152-Reviews'\n",
    "\n",
    "url_last = 'The_Fern_An_Ecotel_Hotel_Jaipur-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_fern = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_fern.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_fern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2c2a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 5.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','The Fern - An Ecotel Hotel', reviews_fern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb99dd7",
   "metadata": {},
   "source": [
    "## 6. Trident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd989c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304555-d300602-Reviews'\n",
    "\n",
    "url_last = 'Trident_Jaipur-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_tri = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_tri.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da6eef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 6.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','Trident', reviews_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cf3cd",
   "metadata": {},
   "source": [
    "## 7. Hilton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85fcff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304555-d6540893-Reviews'\n",
    "\n",
    "url_last = 'Hilton_Jaipur-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_hilton = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_hilton.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f13b9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 7.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','Hilton', reviews_hilton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cdd5ab",
   "metadata": {},
   "source": [
    "## 8. Jaipur Marriott Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5612b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304555-d2151631-Reviews'\n",
    "\n",
    "url_last = 'Jaipur_Marriott_Hotel-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_jai = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_jai.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbb7db81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 8.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','Jaipur Marriott Hotel', reviews_jai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d10f5b",
   "metadata": {},
   "source": [
    "## 9. Clarks Amer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9701abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304555-d456125-Reviews'\n",
    "\n",
    "url_last = 'Clarks_Amer-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_amer = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_amer.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6be81b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 9.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','Clarks Amer', reviews_amer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3b062",
   "metadata": {},
   "source": [
    "## 10. Hotel Golden Tulip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d617c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304555-d6373525-Reviews'\n",
    "\n",
    "url_last = 'Hotel_Golden_Tulip_Jaipur-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_gold = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_gold.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "024cc070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 10.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur','Hotels','Hotel Golden Tulip', reviews_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174f462",
   "metadata": {},
   "source": [
    "# Restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054fea0b",
   "metadata": {},
   "source": [
    "## 1. Hawk View Restaurant & Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbaf6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304555-d12869681-Reviews'\n",
    "\n",
    "url_last = 'Hawk_View_Restaurant_Bar-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_hawk = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_hawk.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ac0d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 11.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Restaurants' , 'Hawk View Restaurant & Bar' , reviews_hawk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc3079",
   "metadata": {},
   "source": [
    "## 2. Jaipur Palace Santorini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86d173ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g644212-d7940038-Reviews'\n",
    "\n",
    "url_last = 'Jaipur_Palace_Santorini-Karteradhos_Santorini_Cyclades_South_Aegean.html'\n",
    "\n",
    "\n",
    "reviews_palace = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_palace.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d93dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 12.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('jaipur' , 'Restaurants' , 'Jaipur Palace Santorini' , reviews_palace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c34689",
   "metadata": {},
   "source": [
    "## 3. Okra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d61dc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304555-d2177263-Reviews'\n",
    "\n",
    "url_last = 'Okra-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_okra = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_okra.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35f28b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 13.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Restaurants' , 'Okra' , reviews_okra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21696f85",
   "metadata": {},
   "source": [
    "## 4. Monarch restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37b9173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304555-d7288570-Reviews'\n",
    "\n",
    "url_last = 'Monarch_Restaurant-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_monarch = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "   \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           \n",
    "            reviews_monarch.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5f4130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 15.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Restaurants' , 'Monarch Restaurant' , reviews_monarch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e18c1",
   "metadata": {},
   "source": [
    "## 5. Jaipur of Chigwell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed6a9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g1635502-d5423532-Reviews'\n",
    "\n",
    "url_last = 'Jaipur_of_Chigwell-Woodford_Redbridge_Greater_London_England.html'\n",
    "\n",
    "\n",
    "reviews_chig = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_chig.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4bbd16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 16.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Restaurants' , 'Jaipur of Chigwell' , reviews_chig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab06676",
   "metadata": {},
   "source": [
    "## 6. Niro's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f62bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304555-d946858-Reviews'\n",
    "\n",
    "url_last = 'Niro_s-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_niro = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_niro.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37bc2fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 17.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Restaurants' , \"Niro's\" , reviews_niro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6725b1",
   "metadata": {},
   "source": [
    "## 7. The Curry Spoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c22faad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304555-d11800643-Reviews'\n",
    "\n",
    "url_last = 'The_Curry_Spoon-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_spoon = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_spoon.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2759604e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 14.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Restaurants' , 'The Curry Spoon' , reviews_spoon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f8a1a4",
   "metadata": {},
   "source": [
    "## 8. Dragon House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66c143b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304555-d1070710-Reviews'\n",
    "\n",
    "url_last = 'Dragon_House-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_drag = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_drag.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cba3787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 18.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Restaurants' , 'Dragon House' , reviews_drag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bdf4c3",
   "metadata": {},
   "source": [
    "## 9. Tapri Pratham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f479d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304555-d3167423-Reviews'\n",
    "\n",
    "url_last = 'Tapri_Pratham-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_tapri = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_tapri.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff6de48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 19.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Restaurants' , 'Tapri Pratham' , reviews_tapri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544e1af",
   "metadata": {},
   "source": [
    "## 10. Spice Court Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b6bb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304555-d1091582-Reviews'\n",
    "\n",
    "url_last = 'Spice_Court_Restaurant-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "\n",
    "\n",
    "reviews_spice = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_spice.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b77c896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 20.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Restaurants' , 'Spice Court Restaurant' , reviews_spice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ffb2ea",
   "metadata": {},
   "source": [
    "# Things to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958fd7fc",
   "metadata": {},
   "source": [
    "## 1. Hawa Mahal - Palace of Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5c2e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304555-d317345-Reviews'\n",
    "\n",
    "url_last = 'Hawa_Mahal_Palace_of_Wind-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "    \n",
    "reviews_hawa = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_hawa.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "518e6ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 21.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'Hawa Mahal - Palace of Wind' , reviews_hawa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1eb49",
   "metadata": {},
   "source": [
    "## 2. Nahargarh Fort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "671b8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304555-d311641-Reviews'\n",
    "\n",
    "url_last = 'Nahargarh_Fort-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "    \n",
    "reviews_fort = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_fort.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6fcdefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 22.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'Nahargarh Fort' , reviews_fort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6d551",
   "metadata": {},
   "source": [
    "## 3. Birla Mandir Temple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac955e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304555-d320081-Reviews'\n",
    "\n",
    "url_last = 'Birla_Mandir_Temple-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "    \n",
    "reviews_birla = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_birla.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e115363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 23.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'Birla Mandir Temple' , reviews_birla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab04934",
   "metadata": {},
   "source": [
    "## 4. Jaigarh Fort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b50d50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304555-d325116-Reviews'\n",
    "\n",
    "url_last = 'Jaigarh_Fort-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "    \n",
    "reviews_jai = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_jai.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f82ce10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 24.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'Jaigarh Fort' , reviews_jai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa0498",
   "metadata": {},
   "source": [
    "## 5. City Palace of Jaipur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49e49279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304555-d324468-Reviews'\n",
    "\n",
    "url_last = 'City_Palace_of_Jaipur-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "    \n",
    "reviews_city = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_city.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b214532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 25.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'City Palace of Jaipur' , reviews_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7ccea",
   "metadata": {},
   "source": [
    "## 6. Elefantastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac056e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304555-d2552789-Reviews'\n",
    "\n",
    "url_last = 'Elefantastic-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "    \n",
    "reviews_ele = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_ele.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "627cd318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 26.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'Elefantastic' , reviews_ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c186b5",
   "metadata": {},
   "source": [
    "## 7. Jantar Mantar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be25c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304555-d311635-Reviews'\n",
    "\n",
    "url_last = 'Jantar_Mantar_Jaipur-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "    \n",
    "reviews_jantar = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_jantar.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "570f0b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 27.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'Jantar Mantar' , reviews_jantar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f26a6",
   "metadata": {},
   "source": [
    "## 8. Amber Palace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c50e82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g1096234-d319875-Reviews'\n",
    "\n",
    "url_last = 'Amber_Palace-Amer_Jaipur_Jaipur_District_Rajasthan.html'\n",
    "    \n",
    "reviews_amber = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_amber.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2197f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 28.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'Amber Palace' , reviews_amber)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6181fa",
   "metadata": {},
   "source": [
    "## 9. Chand Baori (Step well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdecef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g2322083-d1382647-Reviews'\n",
    "\n",
    "url_last = 'Chand_Baori_Step_well-Abhaneri_Dausa_District_Rajasthan.html'\n",
    "    \n",
    "reviews_chand = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_chand.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88394690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 29.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'Chand Baori (Step well)' , reviews_chand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b70a34",
   "metadata": {},
   "source": [
    "## 10. Jal Mahal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "413fa408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304555-d324664-Reviews'\n",
    "\n",
    "url_last = 'Jal_Mahal-Jaipur_Jaipur_District_Rajasthan.html'\n",
    "    \n",
    "reviews_jal = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_jal.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be8a7440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 30.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Jaipur' , 'Things' , 'Jal Mahal' , reviews_jal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

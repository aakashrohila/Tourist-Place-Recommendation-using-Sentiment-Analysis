{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755afe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc1bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "def writer(city_name, place_to_visit, place_name, reviews):\n",
    "    ''' This method is created to create output excel file with ease '''\n",
    "    global counter\n",
    "    \n",
    "    hotel_dict = {'city_name':city_name, 'place_to_visit': place_to_visit, 'place_name': place_name, 'reviews': reviews}\n",
    "    \n",
    "    df=pd.DataFrame(hotel_dict)\n",
    "    folder_path = f'C:\\Modules\\Major Project\\Web_Scrapping\\\\{city_name}\\\\{place_to_visit}\\\\{counter}.xlsx'\n",
    "    \n",
    "    df.to_excel(folder_path, index=False, header=True)\n",
    "    \n",
    "    print('This files has',len(reviews),'rows')\n",
    "    \n",
    "    print(f'File : {counter}.xlsx written to path')\n",
    "    \n",
    "    counter = counter+1\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f74779",
   "metadata": {},
   "source": [
    "# CHANDIGARH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc04bb",
   "metadata": {},
   "source": [
    "# Hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed550b91",
   "metadata": {},
   "source": [
    "## 1. Hometel Chandigarh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d71b20fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297596-d1754192-Reviews'\n",
    "\n",
    "url_last = 'Hometel_Chandigarh-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_hometel = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_hometel.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb179eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 1.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','Hometel Chandigarh', reviews_hometel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbcde52",
   "metadata": {},
   "source": [
    "## 2. Taj Chandigarh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9b69ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297596-d575986-Reviews'\n",
    "\n",
    "url_last = 'Taj_Chandigarh-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_taj = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_taj.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9160c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 2.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','Taj Chandigarh', reviews_taj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86221c3",
   "metadata": {},
   "source": [
    "## 3. JW Marriott Hotel Chandigarh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ebf92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297596-d2065676-Reviews'\n",
    "\n",
    "url_last = 'JW_Marriott_Hotel_Chandigarh-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_jw = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_jw.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5c437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 3.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','JW Marriott Hotel Chandigarh', reviews_jw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e702e",
   "metadata": {},
   "source": [
    "## 4. Hyatt Regency Chandigarh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a6413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297596-d9455441-Reviews'\n",
    "\n",
    "url_last = 'Hyatt_Regency_Chandigarh-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_hyatt = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_hyatt.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d39d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 4.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','Hyatt Regency Chandigarh', reviews_hyatt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34816c3",
   "metadata": {},
   "source": [
    "## 5. Lemon Tree Hotel, Chandigarh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2666c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297596-d2430976-Reviews'\n",
    "\n",
    "url_last = 'Lemon_Tree_Hotel_Chandigarh-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_lemon= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_lemon.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7abd6829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 5.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','Lemon Tree Hotel, Chandigarh', reviews_lemon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee543371",
   "metadata": {},
   "source": [
    "## 6. Radisson Chandigarh Zirakpur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d23056be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g1584814-d14123907-Reviews'\n",
    "\n",
    "url_last = 'Radisson_Chandigarh_Zirakpur-Zirakpur_Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_radisson= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_radisson.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55636dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 6.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','Radisson Chandigarh Zirakpur', reviews_radisson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ab4c1",
   "metadata": {},
   "source": [
    "## 7. Golden Tulip Chandigarh Panchkula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d4d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297616-d3331633-Reviews'\n",
    "\n",
    "url_last = 'Golden_Tulip_Chandigarh_Panchkula-Panchkula_Panchkula_District_Haryana.html'\n",
    "\n",
    "\n",
    "reviews_golden = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_golden.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60208b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 7.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','Golden Tulip Chandigarh Panchkula', reviews_golden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b310e30",
   "metadata": {},
   "source": [
    "## 8. Country Inn & Suites by Radisson Zirakpur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc0aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g1584814-d15262662-Reviews'\n",
    "\n",
    "url_last = 'Country_Inn_Suites_by_Radisson_Zirakpur-Zirakpur_Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_countryinn= []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_countryinn.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d590a649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 8.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','Country Inn & Suites by Radisson Zirakpur', reviews_countryinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e913fd",
   "metadata": {},
   "source": [
    "## 9. The Lalit Chandigarh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf8c34a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297596-d4558938-Reviews'\n",
    "\n",
    "url_last = 'The_Lalit_Chandigarh-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_lalit = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_lalit.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d0f8786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 9.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','The Lalit Chandigarh', reviews_lalit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78492ced",
   "metadata": {},
   "source": [
    "## 10. Hotel Turquoise Chandigarh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d006492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297596-d5031080-Reviews'\n",
    "\n",
    "url_last = 'Hotel_Turquoise_Chandigarh-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_turquoise = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_turquoise.append(review_text.span.text)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06b58958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 10.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh','Hotels','Hotel Turquoise Chandigarh', reviews_turquoise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5fb6aa",
   "metadata": {},
   "source": [
    "# Restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b7349",
   "metadata": {},
   "source": [
    "## 1. Pal Dhaba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10e3bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297596-d1028094-Reviews'\n",
    "\n",
    "url_last = 'Pal_Dhaba-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_pal = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_pal.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40c2aa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 11.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , 'Pal Dhaba' , reviews_pal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114976a9",
   "metadata": {},
   "source": [
    "## 2. Barbeque Nation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "873b470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297596-d1027771-Reviews'\n",
    "\n",
    "url_last = 'Barbeque_Nation-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_nation = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_nation.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65b1957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 12.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , 'Barbeque Nation' , reviews_nation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e5d67",
   "metadata": {},
   "source": [
    "## 3. The Cafe @ JW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dc8b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297596-d3155873-Reviews'\n",
    "\n",
    "url_last = 'The_Cafe_JW-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_jw = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_jw.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ae1c78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 13.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , 'The Cafe @ JW' , reviews_jw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6569fb",
   "metadata": {},
   "source": [
    "## 4. Saffron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e256165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297596-d2693220-Reviews'\n",
    "\n",
    "url_last = 'Saffron-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_saff = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_saff.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1132e2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 14.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , 'Saffron' , reviews_saff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58320c8",
   "metadata": {},
   "source": [
    "## 5. Sindhi's Sweets & Vegetarian Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f4d02f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297596-d3594391-Reviews'\n",
    "\n",
    "url_last = 'Sindhi_s_Sweets_Vegetarian_Restaurants-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_sindhi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_sindhi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e9116f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 15.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , \"Sindhi's Sweets & Vegetarian Restaurants\" , reviews_sindhi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7a276",
   "metadata": {},
   "source": [
    "## 6. Haveli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "890bfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g488276-d1108222-Reviews'\n",
    "\n",
    "url_last = 'Haveli-Jalandhar_Jalandhar_District_Punjab.html'\n",
    "\n",
    "\n",
    "reviews_haveli = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_haveli.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31519f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 16.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , 'Haveli' , reviews_haveli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31087688",
   "metadata": {},
   "source": [
    "## 7. Hot Millions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23e3a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297596-d944203-Reviews'\n",
    "\n",
    "url_last = 'Hot_Millions-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_hot = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_hot.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a0320d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 287 rows\n",
      "File : 17.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , 'Hot Millions' , reviews_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9133a1",
   "metadata": {},
   "source": [
    "## 8. Virgin Courtyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e34c7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297596-d3792344-Reviews'\n",
    "\n",
    "url_last = 'Virgin_Courtyard-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_virgin = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_virgin.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd5c4a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 290 rows\n",
      "File : 18.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , 'Virgin Courtyard' , reviews_virgin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa554a3",
   "metadata": {},
   "source": [
    "## 9. Urban Cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30160110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297596-d10453286-Reviews'\n",
    "\n",
    "url_last = 'Urban_Cafe-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_urban = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_urban.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bedda0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 288 rows\n",
      "File : 19.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , 'Urban Cafe' , reviews_urban)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda502f",
   "metadata": {},
   "source": [
    "## 10. Gopal Sweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5e34c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297596-d3593238-Reviews'\n",
    "\n",
    "url_last = 'Gopal_Sweets-Chandigarh.html'\n",
    "\n",
    "\n",
    "reviews_gopal = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_gopal.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "975fe775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 20.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Restaurants' , 'Gopal Sweets' , reviews_gopal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13afa155",
   "metadata": {},
   "source": [
    "# Things to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4fa08",
   "metadata": {},
   "source": [
    "## 1. The Rock Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddbff23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297596-d1575668-Reviews'\n",
    "\n",
    "url_last = 'The_Rock_Garden_of_Chandigarh-Chandigarh.html'\n",
    "    \n",
    "reviews_rock = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_rock.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b7f37b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 21.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'The Rock Garden' , reviews_rock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b7d67",
   "metadata": {},
   "source": [
    "## 2. Chandigarh Rose Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a45ad524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297596-d1575671-Reviews'\n",
    "\n",
    "url_last = 'Chandigarh_Rose_Garden-Chandigarh.html'\n",
    "    \n",
    "reviews_rose = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_rose.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8add400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 22.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'Chandigarh Rose Garden' , reviews_rose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b7f21",
   "metadata": {},
   "source": [
    "## 3. Sukhna Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be92a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297596-d1204434-Reviews'\n",
    "\n",
    "url_last = 'Sukhna_Lake-Chandigarh.html'\n",
    "    \n",
    "reviews_lake = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_lake.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74a5287d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 23.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'Sukhna Lake' , reviews_lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5fcee",
   "metadata": {},
   "source": [
    "## 4. Pinjore Gardens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c4a1ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g1156018-d1419491-Reviews'\n",
    "\n",
    "url_last = 'Pinjore_Gardens-Pinjore_Panchkula_District_Haryana.html'\n",
    "    \n",
    "reviews_pin = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_pin.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14483084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 254 rows\n",
      "File : 24.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'Pinjore Gardens' , reviews_pin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8b956",
   "metadata": {},
   "source": [
    "## 5. Timber Trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3d8351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297596-d3923630-Reviews'\n",
    "\n",
    "url_last = 'Timber_Trail-Chandigarh.html'\n",
    "    \n",
    "reviews_trail = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_trail.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9c83ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 25.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'Timber Trail' , reviews_trail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12dc47f",
   "metadata": {},
   "source": [
    "## 6. Spiti Valley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f910d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297617-d1469237-Reviews'\n",
    "\n",
    "url_last = 'Spiti_Valley-Himachal_Pradesh.html'\n",
    "    \n",
    "reviews_spiti = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_spiti.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "60735fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 26.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'Spiti Valley' , reviews_spiti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c7e14",
   "metadata": {},
   "source": [
    "## 7. Manki Point - Hanuman Temple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67bcef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g1152631-d2263108-Reviews'\n",
    "\n",
    "url_last = 'Manki_Point_Hanuman_Temple-Kasauli_Kasauli_Tehsil_Solan_District_Himachal_Prades.html'\n",
    "    \n",
    "reviews_manki = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_manki.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13d41120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 27.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'Manki Point - Hanuman Temple' , reviews_manki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78972797",
   "metadata": {},
   "source": [
    "## 8. Chitkul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "562e6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g1214902-d8015874-Reviews'\n",
    "\n",
    "url_last = 'Chitkul-Sangla_Kinnaur_District_Himachal_Pradesh.html'\n",
    "    \n",
    "reviews_chit = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_chit.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a262183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 28.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'Chitkul' , reviews_chit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90451ad4",
   "metadata": {},
   "source": [
    "## 9. Sunset Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec1d4d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g1152631-d2342609-Reviews'\n",
    "\n",
    "url_last = 'Sunset_Point-Kasauli_Kasauli_Tehsil_Solan_District_Himachal_Pradesh.html'\n",
    "    \n",
    "reviews_sun = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sun.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48ca0e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 29.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'Sunset Point' , reviews_sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121306b",
   "metadata": {},
   "source": [
    "## 10. Elante mall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5c1845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297596-d4186436-Reviews'\n",
    "\n",
    "url_last = 'Elante_mall-Chandigarh.html'\n",
    "    \n",
    "reviews_mall = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_mall.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8ed6a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 30.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Chandigarh' , 'Things' , 'Elante mall' , reviews_mall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

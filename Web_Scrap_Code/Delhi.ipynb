{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Delhi**"
      ],
      "metadata": {
        "id": "EsS7Kom--9xr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hotels**"
      ],
      "metadata": {
        "id": "7lyINHlq_CLq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "77mrHFeya365"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.Taj_Palace_New_Delhi**"
      ],
      "metadata": {
        "id": "5D6B0pz9b9Sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 1\n",
        "def writer(city_name , place_to_visit, place_name , reviews):\n",
        "    ''' This method is created to create output excel file with ease '''\n",
        "    global counter\n",
        "    \n",
        "    hotel_dict = {'city_name' : city_name , 'place_to_visit' : place_to_visit , 'place_name' : place_name , 'reviews' : reviews}\n",
        "    \n",
        "    df = pd.DataFrame(hotel_dict)\n",
        "    \n",
        "    folder_path = f'C:\\\\Users\\\\Desktop\\\\Web_scrapping\\\\{city_name}\\\\{place_to_visit}\\\\{counter}.xlsx'\n",
        "    \n",
        "    df.to_excel( folder_path , index = False , header = True)\n",
        "    \n",
        "    print('This files has',len(reviews),'rows')\n",
        "    \n",
        "    print(f'File : {counter}.xlsx  written to path' )\n",
        "    \n",
        "    counter = counter + 1"
      ],
      "metadata": {
        "id": "2FiRnAiobBRy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d302181-Reviews'\n",
        "\n",
        "url_last = 'Taj_Palace_New_Delhi-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "\n",
        "reviews_Taj_Palace_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Taj_Palace_New_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_Taj_Palace_New_Delhi)\n"
      ],
      "metadata": {
        "id": "z1iTeBRDbBVP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'Taj_Palace_New_Delhi' , reviews_Taj_Palace_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_i8miPabBX0",
        "outputId": "64141f3f-2444-4a9b-856a-3aad8dc69ae9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 23.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.**The Leela Palace New Delhi**"
      ],
      "metadata": {
        "id": "x_mGG_XLcG_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d1759051-Reviewss'\n",
        "\n",
        "url_last = 'The_Leela_Palace_New_Delhi-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "\n",
        "reviews_The_Leela_Palace_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_The_Leela_Palace_New_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_Leela_Palace_New_Delhi)\n"
      ],
      "metadata": {
        "id": "q9zfNn9wcIi6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'The_Leela_Palace_New_Delhi' , reviews_The_Leela_Palace_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzTgFKyycImH",
        "outputId": "67a9cd53-d003-4caf-d9c1-63ec1fddd303"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 24.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.The_Lalit_New_Delhi**"
      ],
      "metadata": {
        "id": "6afMNQtMcwEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d299120-Reviews'\n",
        "\n",
        "url_last = 'The_Lalit_New_Delhi-New_Delhi_National_Capital_Territory_of_Delhi.htmll'\n",
        "\n",
        "\n",
        "reviews_The_Lalit_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_The_Lalit_New_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_Lalit_New_Delhi)\n"
      ],
      "metadata": {
        "id": "BMz2yDracIos"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'The_Lalit_New_Delhi' , reviews_The_Lalit_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHUeoPyVcIrT",
        "outputId": "6087ee91-6a00-41ee-9c63-76a892842bab"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 25.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.**Andaz Delhi**"
      ],
      "metadata": {
        "id": "PUQt5gyUcx88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d11926258-Reviews'\n",
        "\n",
        "url_last = 'Andaz_Delhi-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "\n",
        "reviews_Andaz_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Andaz_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_Andaz_Delhi)\n"
      ],
      "metadata": {
        "id": "0pZlzvOhcIt_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'Andaz_Delhi' , reviews_Andaz_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qmej84_cIxR",
        "outputId": "80f03d66-2627-4e6c-9590-f4ae3eb52c3e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 26.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.The_Oberoi_New_Delhi**"
      ],
      "metadata": {
        "id": "kSxHT3Tyczys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d304216-Reviews'\n",
        "\n",
        "url_last = 'The_Oberoi_New_Delhi-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "\n",
        "reviews_The_Oberoi_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_The_Oberoi_New_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_Oberoi_New_Delhi)\n"
      ],
      "metadata": {
        "id": "9Tw8Q-nycI00"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'The_Oberoi_New_Delhi' , reviews_The_Oberoi_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebsun7rrcI3i",
        "outputId": "a7a5fde3-654f-4941-e481-d31ed161083f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 28.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.**The_Claridges_New_Delhi**"
      ],
      "metadata": {
        "id": "iYI6guRSc2kN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d306937-Reviews'\n",
        "\n",
        "url_last = 'The_Claridges_New_Delhi-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "\n",
        "reviews_The_Claridges_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_The_Claridges_New_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_Claridges_New_Delhi)\n"
      ],
      "metadata": {
        "id": "SbL0RPucbBa0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'The_Claridges_New_Delhi' , reviews_The_Claridges_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SM5tQoNbBd5",
        "outputId": "2170b850-63af-4604-9ce3-33c3c92b5603"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 29.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.**The_Suryaa_New_Delhi**"
      ],
      "metadata": {
        "id": "4TmtJfF8c3zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d306949-Reviews'\n",
        "\n",
        "url_last = 'The_Suryaa_New_Delhi_New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "\n",
        "reviews_The_Suryaa_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_The_Suryaa_New_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_The_Suryaa_New_Delhi)\n"
      ],
      "metadata": {
        "id": "mKfZst-hbB-4"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'The_Suryaa_New_Delhi' , reviews_The_Suryaa_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMsKMFeFcksr",
        "outputId": "1d8d3e53-1e3b-4a08-86a6-c7c08fe2a2c4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 30.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.**Radisson**"
      ],
      "metadata": {
        "id": "8jFS8VCcc5Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d306957-Reviews'\n",
        "\n",
        "url_last = 'Radisson_Blu_Plaza_Delhi_Airport-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "\n",
        "reviews_Radisson_Blu_Plaza_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Radisson_Blu_Plaza_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_Radisson_Blu_Plaza_Delhi)\n"
      ],
      "metadata": {
        "id": "xLhcAxLQckwH"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'Radisson' , reviews_Radisson)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ms-QkMlckzg",
        "outputId": "5e849f34-913e-4b6f-8417-740b0ad3e063"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 31.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.**Le_Meridien_New_Delhi**"
      ],
      "metadata": {
        "id": "r-Qf2gdcc6PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d301904-Reviews'\n",
        "\n",
        "url_last = 'Le_Meridien_New_Delhi-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "\n",
        "reviews_Le_Meridien_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Le_Meridien_New_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_Le_Meridien_New_Delhi)\n"
      ],
      "metadata": {
        "id": "RFtbpcUVck2i"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'Le_Meridien_New_Delhi' , reviews_Le_Meridien_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujh9Ud6Mck6A",
        "outputId": "a97666c0-5160-45bf-fa48-004d2f2f7b90"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 32.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.**JW_Marriott_Hotel_New_Delhi**"
      ],
      "metadata": {
        "id": "0f50LACZc7Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304551-d4451234-Reviews'\n",
        "\n",
        "url_last = 'JW_Marriott_Hotel_New_Delhi_Aerocity-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "\n",
        "reviews_JW_Marriott_Hotel_New_Delhi= []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
        "\n",
        "    for r in review_div:\n",
        "\n",
        "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_JW_Marriott_Hotel_New_Delhi.append(review_text.span.text)\n",
        "            \n",
        "#print(reviews_JW_Marriott_Hotel_New_Delhi)\n"
      ],
      "metadata": {
        "id": "xnqu1LUyck8z"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Hotels' , 'JW_Marriott_Hotel_New_Delhi' , reviews_JW_Marriott_Hotel_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84pN17V7clAM",
        "outputId": "8e8ca534-7441-4689-d812-4ed92b325944"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 33.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Restaurants**"
      ],
      "metadata": {
        "id": "k6qCVRWYqCF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.Nu_Delhi"
      ],
      "metadata": {
        "id": "GxcfgDOrqIH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g186470-d2360795-Reviews'\n",
        "\n",
        "url_last = 'Nu_Delhi-Belfast_Northern_Ireland.html'\n",
        "\n",
        "reviews_Nu_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Nu_Delhi.append(review_text.text)"
      ],
      "metadata": {
        "id": "Gvq8oEUYbCCA"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , 'Nu_Delhi' , reviews_Nu_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht0AVsY3qUso",
        "outputId": "65faa8a3-7cbc-419d-d360-2efb83c9c043"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 34.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.**Delhi_Darbar**"
      ],
      "metadata": {
        "id": "H9lg2G0xsdpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g662606-d12619450-Reviews'\n",
        "\n",
        "url_last = 'Delhi_Darbar-Costa_Adeje_Adeje_Tenerife_Canary_Islands.html'\n",
        "\n",
        "reviews_Delhi_Darbar = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Delhi_Darbar.append(review_text.text)"
      ],
      "metadata": {
        "id": "_ogaiZO0qU4s"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , 'Delhi_Darbar' , reviews_Delhi_Darbar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNFl0i-8sZN8",
        "outputId": "1167e318-15f6-440c-f4ce-4c87fb349267"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 36.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.Gulati-New_Delhi**"
      ],
      "metadata": {
        "id": "3O-hwAgCsfPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304551-d790553-Reviews'\n",
        "\n",
        "url_last = 'Gulati_New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "reviews_Gulati_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Gulati_New_Delhi.append(review_text.text)"
      ],
      "metadata": {
        "id": "iElPGDj2sZdf"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , 'Gulati-New_Delhi' , reviews_Gulati_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEjLkFFVsZgr",
        "outputId": "6ee7933b-61cf-45ba-c28b-a4890ca38587"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 37.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.**Karim_s_New_Delhi**"
      ],
      "metadata": {
        "id": "6SjRZeujsf5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304551-d815173-Reviews'\n",
        "\n",
        "url_last = 'Karim_s_New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "reviews_Karim_s_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Karim_s_New_Delhi.append(review_text.text)"
      ],
      "metadata": {
        "id": "r4kj-v3qsZlS"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , 'Karim_s_New_Delhi' , reviews_Karim_s_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEClqhXBsZpL",
        "outputId": "bc4fd0a7-8472-4c27-db80-0c4000f2dea0"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 38.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.**Indian_Accent_New_Delhi**"
      ],
      "metadata": {
        "id": "366ZzcbqshQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304551-d1417229-Reviews'\n",
        "\n",
        "url_last = 'Indian_Accent_New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "reviews_Indian_Accent_New_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Indian_Accent_New_Delhi.append(review_text.text)"
      ],
      "metadata": {
        "id": "loUgJJsLsZub"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , 'Indian_Accent_New_Delhi' , reviews_Indian_Accent_New_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2owP6so_saC9",
        "outputId": "1a7a9561-793f-4bca-ef7b-3cb0a3025134"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 39.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.**Saravana_Bhavan**"
      ],
      "metadata": {
        "id": "_3ahKi7TsiDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304551-d1115470-Reviews'\n",
        "\n",
        "url_last = 'Saravana_Bhavan-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "reviews_Saravana_Bhavan = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Saravana_Bhavan.append(review_text.text)"
      ],
      "metadata": {
        "id": "ngS2Q6lbsaIk"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , 'Saravana_Bhavan' , reviews_Saravana_Bhavan)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wQD5vFjsaMa",
        "outputId": "1dcbfbdb-8f43-4c2b-833e-5a0f033276d0"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 40.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.Shang_Palace**"
      ],
      "metadata": {
        "id": "3xV2elztsi6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304551-d9842401-Reviews'\n",
        "\n",
        "url_last = 'Shang_Palace-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "reviews_Shang_Palace = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Shang_Palace.append(review_text.text)"
      ],
      "metadata": {
        "id": "REWfKPn4sadR"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , 'Shang_Palace' , reviews_Shang_Palace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UMUISclqU8Y",
        "outputId": "e0767d40-6132-492e-801f-4d29268a4448"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 41.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.**Royal_Delhi**"
      ],
      "metadata": {
        "id": "8Bf0RBYHsjkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g528752-d10846291-Reviews'\n",
        "\n",
        "url_last = 'Royal_Delhi-Brighouse_West_Yorkshire_England.html'\n",
        "\n",
        "reviews_Royal_Delhi = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_Royal_Delhi.append(review_text.text)"
      ],
      "metadata": {
        "id": "WXKQ96W6qVAA"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , 'Royal_Delhi' , reviews_Royal_Delhi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TgClOT4qVDF",
        "outputId": "104cfa3c-89d1-4b5f-c81d-2577af91b521"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 42.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.**The_Spice_Route**"
      ],
      "metadata": {
        "id": "6HNk4iSSskLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304551-d795796-Reviews'\n",
        "\n",
        "url_last = 'The_Spice_Route-New_Delhi_National_Capital_Territory_of_Delhi.html'\n",
        "\n",
        "reviews_The_Spice_Route = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_The_Spice_Route.append(review_text.text)"
      ],
      "metadata": {
        "id": "0b15dmqxskmO"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , 'The_Spice_Route' , reviews_The_Spice_Route)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfSah0erskrJ",
        "outputId": "6602267d-87ff-4d5a-e92c-f036b338e06c"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 43.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.**4550_miles**"
      ],
      "metadata": {
        "id": "J5gro29TsyHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g186356-d2062401-Reviews'\n",
        "\n",
        "url_last = '4550_miles_from_Delhi-Nottingham_Nottinghamshire_England.html'\n",
        "\n",
        "reviews_4550_miles = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(15,310,15):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
        "    \n",
        "    \n",
        "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
        "    \n",
        "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
        "    \n",
        "    for t in tags_to_delete:\n",
        "        t.decompose()\n",
        "    \n",
        "\n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('p' , class_ = 'partial_entry')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #review_text.span.decompose()\n",
        "            #print(review_text.text)\n",
        "            #print()\n",
        "            reviews_4550_miles.append(review_text.text)"
      ],
      "metadata": {
        "id": "I_auu-bjskuH"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Restaurant' , '4550_miles' , reviews_4550_miles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bvc1gA4skxX",
        "outputId": "7f7c5a01-3416-452e-dc39-bf252814a248"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 44.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Things to do**"
      ],
      "metadata": {
        "id": "m3ODkka-2k5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.**Connaught_Place**"
      ],
      "metadata": {
        "id": "FgaDn6Nx5A0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d324103-Reviews'\n",
        "\n",
        "url_last = 'Connaught_Place-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_Connaught_Place = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Connaught_Place.append(review_text.text)"
      ],
      "metadata": {
        "id": "Zwej46zg2kFt"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'Connaught_Place' , reviews_Connaught_Place)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2rRUwvosk1K",
        "outputId": "5c5ad965-b0b8-4a85-b1f8-2bc2f5a92d22"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 45.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.**Qutub_Minar**"
      ],
      "metadata": {
        "id": "D_KWZMGi3-6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d311626-Reviews'\n",
        "\n",
        "url_last = 'Qutub_Minar-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_Qutub_Minar = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Qutub_Minar.append(review_text.text)"
      ],
      "metadata": {
        "id": "KSWh9YJ54I6I"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'Qutub_Minar' , reviews_Qutub_Minar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3YtFL7V2GQc",
        "outputId": "139c899e-87da-43ec-8dd7-45987dac3002"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 46.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.**India_Gate**"
      ],
      "metadata": {
        "id": "wYfrZMcu3_iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d321493-Reviews'\n",
        "\n",
        "url_last = 'India_Gate-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_India_Gate = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_India_Gate.append(review_text.text)"
      ],
      "metadata": {
        "id": "nyq-AYR32GT2"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'India_Gate' , reviews_India_Gate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNMj64oN4NST",
        "outputId": "2cbaea6c-e56f-40ac-dd7a-fe82dfa6d932"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 47.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.**Lodhi_Garden**"
      ],
      "metadata": {
        "id": "a2pf14Mt4ART"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d324106-Reviews'\n",
        "\n",
        "url_last = 'Lodhi_Garden-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_Lodhi_Garden = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Lodhi_Garden.append(review_text.text)"
      ],
      "metadata": {
        "id": "OWgWYRHr2GX1"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'Lodhi_Garden' , reviews_Lodhi_Garden)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bxb92ib2GdY",
        "outputId": "667cdd1e-c9a3-484f-8376-43c003fe185b"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 48.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.**Red_Fort**"
      ],
      "metadata": {
        "id": "8blS5cK34BBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d319701-Reviews'\n",
        "\n",
        "url_last = '5.Red_Fort-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_Red_Fort = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Red_Fort.append(review_text.text)"
      ],
      "metadata": {
        "id": "UxBydXSp2Gjz"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'Red_Fort' , reviews_Red_Fort)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA5sqetbqVGR",
        "outputId": "998a54ef-ae73-46c6-eead-15f396a58638"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 49.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.**Chandni_Chowk**"
      ],
      "metadata": {
        "id": "X69fOmuU4S8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d311613-Reviews'\n",
        "\n",
        "url_last = 'Chandni_Chowk-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_Chandni_Chowk = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Chandni_Chowk.append(review_text.text)"
      ],
      "metadata": {
        "id": "rpcadJDW4RHI"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'Chandni_Chowk' , reviews_Chandni_Chowk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD-LBSB74RLk",
        "outputId": "049f47fc-37cf-4f24-a718-74ccca83e643"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 50.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.**Humayun_s_Tomb**"
      ],
      "metadata": {
        "id": "udb-JCDm4U7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d311618-Reviews'\n",
        "\n",
        "url_last = 'Humayun_s_Tomb-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_Humayun_s_Tomb = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Humayun_s_Tomb.append(review_text.text)"
      ],
      "metadata": {
        "id": "EbV39xQ84RQb"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'Humayun_s_Tomb' , reviews_Humayun_s_Tomb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVwGaS4P4RUr",
        "outputId": "24528a7a-7372-4d24-b0f2-99da75badda2"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 51.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.**Swaminarayan_Akshardham**"
      ],
      "metadata": {
        "id": "M6DLqKBm4V2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d626913-Reviews'\n",
        "\n",
        "url_last = 'Swaminarayan_Akshardham-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_Swaminarayan_Akshardham = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Swaminarayan_Akshardham.append(review_text.text)"
      ],
      "metadata": {
        "id": "B0LK7k_I4RYN"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'Swaminarayan_Akshardham' , reviews_Swaminarayan_Akshardham)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cFyxbIi4Rby",
        "outputId": "09109407-faf8-4d56-a921-0a2e10821862"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 52.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.**Gurudwara_Bangla_Sahib**"
      ],
      "metadata": {
        "id": "3VnH_bPa4Wz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d3681196-Reviews'\n",
        "\n",
        "url_last = 'Gurudwara_Bangla_Sahib-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_Gurudwara_Bangla_Sahib = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Gurudwara_Bangla_Sahib.append(review_text.text)"
      ],
      "metadata": {
        "id": "MQmNF-4q4Rsz"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'Gurudwara_Bangla_Sahib' , reviews_Gurudwara_Bangla_Sahib)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfA9viiI4Rwt",
        "outputId": "16f6efe9-afba-4098-e797-e1f62a7d4b42"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 53.xlsx  written to path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.**Lotus_Temple**"
      ],
      "metadata": {
        "id": "KCwb0fe_4Yoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining user\n",
        "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
        "\n",
        "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304551-d311659-Reviews'\n",
        "\n",
        "url_last = 'Lotus_Temple-New_Delhi_National_Capital_Territory_of_Delhi.html'    \n",
        "    \n",
        "reviews_Lotus_Temple = []\n",
        "\n",
        "#This loop was necessary to go to next page on trip advisor\n",
        "for x in range(10,310,10):\n",
        "    #This url_mid will change va\n",
        "    url_mid = '-or' + str(x) + '-'\n",
        "    \n",
        "    url = url_first + url_mid + url_last\n",
        "\n",
        "    html_text = requests.get( url , headers = user_agent).text\n",
        "    \n",
        "    soup = BeautifulSoup(html_text , 'html.parser')\n",
        "\n",
        "    review_div = soup.find_all('div' , class_ = '_c')\n",
        "    \n",
        "    \n",
        "    for r in review_div:\n",
        "        \n",
        "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
        "        \n",
        "        if review_text != None:\n",
        "            #print(review_text.span.text)\n",
        "            #print()\n",
        "            reviews_Lotus_Temple.append(review_text.text)"
      ],
      "metadata": {
        "id": "3HuIupfX4XpD"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer('Delhi' , 'Things' , 'Lotus_Temple' , reviews_Lotus_Temple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNX1pBKu4YAC",
        "outputId": "18165784-3595-45cc-c6d1-8628e9e3bb5e"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This files has 300 rows\n",
            "File : 54.xlsx  written to path\n"
          ]
        }
      ]
    }
  ]
}
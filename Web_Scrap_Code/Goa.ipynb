{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4236a5b0",
   "metadata": {},
   "source": [
    "https://www.tripadvisor.in/Tourism-g297604-Goa-Vacations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78baf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffc8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "def writer(city_name , place_to_visit, place_name , reviews):\n",
    "    ''' This method is created to create output excel file with ease '''\n",
    "    global counter\n",
    "    \n",
    "    hotel_dict = {'city_name' : city_name , 'place_to_visit' : place_to_visit , 'place_name' : place_name , 'reviews' : reviews}\n",
    "    \n",
    "    df = pd.DataFrame(hotel_dict)\n",
    "    \n",
    "    folder_path = f'C:\\Major Project\\Web_Scapping\\\\{city_name}\\\\{place_to_visit}\\\\{counter}.xlsx'\n",
    "    \n",
    "    df.to_excel( folder_path , index = False , header = True)\n",
    "    \n",
    "    print('This files has',len(reviews),'rows')\n",
    "    \n",
    "    print(f'File : {counter}.xlsx  written to path' )\n",
    "    \n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b556f79",
   "metadata": {},
   "source": [
    "## Hotels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c6530",
   "metadata": {},
   "source": [
    "## Taj Resort & Convention Centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e89ed8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g303877-d20183615-Reviews'\n",
    "\n",
    "url_last = 'Taj_Resort_Convention_Centre_Goa-Panjim_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_taj = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_taj.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "708283da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 1.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'Taj Resort & Convention Centre' , reviews_taj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08efff4",
   "metadata": {},
   "source": [
    "## Novotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07d3f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297605-d6499143-Reviews'\n",
    "\n",
    "url_last = 'Novotel_Goa_Resort_Spa-Candolim_Bardez_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_novotel = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_novotel.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b131525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 2.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'Novotel' , reviews_novotel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e75761",
   "metadata": {},
   "source": [
    "## The LaLiT Golf & Spa Resort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1050c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g306996-d299125-Reviews'\n",
    "\n",
    "url_last = 'The_LaLiT_Golf_Spa_Resort_Goa-Canacona_South_Goa_District_Goa.html'\n",
    "\n",
    "reviews_lalit = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_lalit.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ecff911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 3.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'The LaLiT Golf & Spa Resort' , reviews_lalit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5f5e8",
   "metadata": {},
   "source": [
    "## Sobit Sarovar Portico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17bc9a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g2334950-d18933679-Reviews'\n",
    "\n",
    "url_last = 'Sobit_Sarovar_Portico-Palolem_Canacona_South_Goa_District_Goa.html'\n",
    "\n",
    "reviews_sobit = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sobit.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d5639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 4.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'Sobit Sarovar Portico' , reviews_sobit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368680bb",
   "metadata": {},
   "source": [
    "## Hard Rock Hotel Goa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e866274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g306995-d5485906-Reviews'\n",
    "\n",
    "url_last = 'Hard_Rock_Hotel_Goa-Calangute_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_hard = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,315,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser') \n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_hard.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c1628d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 310 rows\n",
      "File : 31.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'Hard Rock Hotel' , reviews_hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d12add",
   "metadata": {},
   "source": [
    "6. Caravela Beach Resort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d060d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g1096236-d306969-Reviews'\n",
    "\n",
    "url_last = 'Caravela_Beach_Resort-Varca_Salcette_South_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_caravela = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_caravela.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f03c640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 6.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'Caravela Beach Resort' , reviews_caravela)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a35c1d",
   "metadata": {},
   "source": [
    "7. Om Sai Beach Huts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48120f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g816969-d1220372-Reviews'\n",
    "\n",
    "url_last = 'Om_Sai_Beach_Huts-Agonda_South_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_om = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,315,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_om.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd007a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 310 rows\n",
      "File : 7.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'Om Sai Beach Huts' , reviews_om)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979dff5b",
   "metadata": {},
   "source": [
    "8. Whispering Palms Beach Resort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "659e7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297605-d315595-Reviews'\n",
    "\n",
    "url_last = 'Whispering_Palms_Beach_Resort-Candolim_Bardez_North_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_palms = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_palms.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1d977c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 8.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'Whispering Palms Beach Resort' , reviews_palms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e3d57f",
   "metadata": {},
   "source": [
    "9. Antares Beach Resort and Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62ad9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g1204883-d9459469-Reviews'\n",
    "\n",
    "url_last = 'Antares_Beach_Resort_and_Club-Vagator_North_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_antares = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_antares.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5c82ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 9.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'Antares Beach Resort and Club' , reviews_antares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ba09a",
   "metadata": {},
   "source": [
    "10. Fenicia Riverside Resort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb3a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g13472226-d2041908-Reviews'\n",
    "\n",
    "url_last = 'Fenicia_Riverside_Resort-Velim_South_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_Fenicia = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_Fenicia.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3271152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 10.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Hotels' , 'Fenicia Riverside Resort' , reviews_Fenicia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec19f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53062cbd",
   "metadata": {},
   "source": [
    "# Restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3ec64",
   "metadata": {},
   "source": [
    "## Copperleaf Porvorim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70a4328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g1962903-d9729522-Reviews'\n",
    "\n",
    "url_last = 'Copperleaf_Porvorim-Alto_Porvorim_North_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_cooper = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_cooper.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e860f158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 11.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , 'Copperleaf Porvorim' , reviews_cooper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531384df",
   "metadata": {},
   "source": [
    "## Pickled Mango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac97517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g312680-d2085082-Reviews'\n",
    "\n",
    "url_last = 'Pickled_Mango-Arpora_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_pickled = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,325,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_pickled.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "938847e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 303 rows\n",
      "File : 12.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , 'Pickled Mango' , reviews_pickled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d4bd9",
   "metadata": {},
   "source": [
    "## Spicy Bella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9034b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g306995-d21264525-Reviews'\n",
    "\n",
    "url_last = 'Spicy_Bella-Calangute_North_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_bella = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_bella.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca1e6831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 13.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , 'Spicy Bella' , reviews_bella)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ef24a",
   "metadata": {},
   "source": [
    "## Relish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95812935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g635747-d5585169-Reviews'\n",
    "\n",
    "url_last = 'Relish-Baga_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_relish = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_relish.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea0707d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 14.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , 'Relish' , reviews_relish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86410a",
   "metadata": {},
   "source": [
    "## Tuscany Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "934de04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297605-d1498092-Reviews'\n",
    "\n",
    "url_last = 'Tuscany_Gardens-Candolim_Bardez_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_tus = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_tus.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "269ff790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 15.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , 'Tuscany Garden' , reviews_tus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa1eabc",
   "metadata": {},
   "source": [
    "6. Sea Breeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7244d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g816969-d11844352-Reviews'\n",
    "\n",
    "url_last = 'Sea_Breeze-Agonda_South_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_sea = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_sea.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc9f5775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 16.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , 'Sea Breeze' , reviews_sea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e91892e",
   "metadata": {},
   "source": [
    "7. Joecons Beach Shack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2d66f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g306994-d7706789-Reviews'\n",
    "\n",
    "url_last = 'Joecons_Beach_Shack-Benaulim_Salcette_South_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_joe = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_joe.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "636e22c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 17.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , 'Joecons Beach Shack' , reviews_joe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0b65f",
   "metadata": {},
   "source": [
    "8. Zest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac47e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g2334950-d7355965-Reviews'\n",
    "\n",
    "url_last = 'Zest-Palolem_Canacona_South_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_Zest = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_Zest.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea55d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 18.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , 'Zest' , reviews_Zest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa5fd6",
   "metadata": {},
   "source": [
    "9. Spice Goa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b85f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g1438385-d3802431-Reviews'\n",
    "\n",
    "url_last = 'Spice_Goa-Mapusa_North_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_spice = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_spice.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6648856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 19.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , 'Spice Goa' , reviews_spice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f6bf4",
   "metadata": {},
   "source": [
    "10. Jardin d'Ulysse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "535a9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g1936425-d2452986-Reviews'\n",
    "\n",
    "url_last = 'Jardin_d_Ulysse-Morjim_North_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_jar  = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,320,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #review_text.span.decompose()\n",
    "            reviews_jar.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f0f27a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 311 rows\n",
      "File : 20.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Restaurants' , \"Jardin d'Ulysse\" , reviews_jar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0d075b",
   "metadata": {},
   "source": [
    "# Things to Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7317f6",
   "metadata": {},
   "source": [
    "## Palolem Beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b8720c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g306996-d482982-Reviews'\n",
    "\n",
    "url_last = 'Palolem_Beach-Canacona_South_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_pal = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_pal.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0669c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 21.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Palolem Beach' , reviews_pal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce5f146",
   "metadata": {},
   "source": [
    "## Dudhsagar Falls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "117aae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g1833171-d3187540-Reviews'\n",
    "\n",
    "url_last = 'Dudhsagar_Falls-Mollem_National_Park_South_Goa_District_Goa.html'\n",
    "\n",
    "\n",
    "reviews_dud = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_dud.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "844b1272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 22.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Dudhsagar Falls' , reviews_dud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba03a7",
   "metadata": {},
   "source": [
    "## Naval Aviation Museum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1bc91001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g2531484-d2209802-Reviews'\n",
    "\n",
    "url_last = 'Naval_Aviation_Museum-Mormugao_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_nav = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,6):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_nav.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47adb4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 309 rows\n",
      "File : 35.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Naval Aviation Museum' , reviews_nav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6744cdf",
   "metadata": {},
   "source": [
    "## Baga Beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa27f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g635747-d2697362-Reviews'\n",
    "\n",
    "url_last = 'Baga_Beach-Baga_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_baga = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_baga.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e8176c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 24.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Baga Beach' , reviews_baga)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2446f7",
   "metadata": {},
   "source": [
    "## Chapora Fort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4bfe575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g2531348-d2345653-Reviews'\n",
    "\n",
    "url_last = 'Chapora_Fort-Chapora_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_fort = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_fort.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e27639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 25.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Chapora Fort' , reviews_fort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf4b649",
   "metadata": {},
   "source": [
    "6. Benaulim Beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6673f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g306994-d2523894-Reviews'\n",
    "\n",
    "url_last = 'Benaulim_Beach-Benaulim_Salcette_South_Goa_District_Goa.html'\n",
    "\n",
    "reviews_ben = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_ben.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "083a7ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 26.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Benaulim Beach' , reviews_ben)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6683e1",
   "metadata": {},
   "source": [
    "7. Basilica of Bom Jesus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10bf6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g306994-d2523894-Reviews'\n",
    "\n",
    "url_last = 'Basilica_of_Bom_Jesus-Goa_Velha_Goa.html'\n",
    "\n",
    "reviews_bas = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_bas.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2196557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 27.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Basilica of Bom Jesus' , reviews_bas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff6f3b",
   "metadata": {},
   "source": [
    "8. Sheek Emporium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ffa75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297605-d2639551-Reviews'\n",
    "\n",
    "url_last = 'Sheek_Emporium_Armanii_Boutique_Since_1950-Candolim_Bardez_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_sheek = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sheek.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07ce7733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 28.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Sheek Emporium ' , reviews_sheek)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b46be",
   "metadata": {},
   "source": [
    "9. Fort Aguada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b662ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g1165042-d1471459-Reviews'\n",
    "\n",
    "url_last = 'Fort_Aguada-Sinquerim_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_agu = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_agu.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1eed22bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 29.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Fort Aguada' , reviews_agu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a81fd8",
   "metadata": {},
   "source": [
    "10. Se Cathedral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3371d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g303877-d320660-Reviews'\n",
    "\n",
    "url_last = 'Se_Cathedral-Panjim_North_Goa_District_Goa.html'\n",
    "\n",
    "reviews_se = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_se.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2796cb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 30.xlsx  written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Goa' , 'Things' , 'Se Cathedral' , reviews_se)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

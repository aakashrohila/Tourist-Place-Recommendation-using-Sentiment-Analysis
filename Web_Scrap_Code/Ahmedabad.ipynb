{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c8e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2e5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "def writer(city_name, place_to_visit, place_name, reviews):\n",
    "    ''' This method is created to create output excel file with ease '''\n",
    "    global counter\n",
    "    \n",
    "    hotel_dict = {'city_name':city_name, 'place_to_visit': place_to_visit, 'place_name': place_name, 'reviews': reviews}\n",
    "    \n",
    "    df=pd.DataFrame(hotel_dict)\n",
    "    folder_path = f'C:\\Modules\\Major Project\\Web_Scrapping\\\\{city_name}\\\\{place_to_visit}\\\\{counter}.xlsx'\n",
    "    \n",
    "    df.to_excel(folder_path, index=False, header=True)\n",
    "    \n",
    "    print('This files has',len(reviews),'rows')\n",
    "    \n",
    "    print(f'File : {counter}.xlsx written to path')\n",
    "    \n",
    "    counter = counter+1\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ad32e",
   "metadata": {},
   "source": [
    "# AHMEDABAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c7c53c",
   "metadata": {},
   "source": [
    "# Hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40f5f6",
   "metadata": {},
   "source": [
    "## 1. Grand Mercure Gandhinagar Gift City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57ce3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297609-d19617346-Reviews'\n",
    "\n",
    "url_last = 'Grand_Mercure_Gandhinagar_Gift_City-Gandhinagar_Gandhinagar_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_grand = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "    \n",
    "    \n",
    "      #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'ajLyr')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_grand.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_grand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02252f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 1.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','Grand Mercure Gandhinagar Gift City', reviews_grand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbb060",
   "metadata": {},
   "source": [
    "## 2. Belvedere Golf & Country Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a610a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297608-d17384006-Reviews'\n",
    "\n",
    "url_last = 'Belvedere_Golf_Country_Club-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_belvedere = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_belvedere.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_belvedere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d42960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 298 rows\n",
      "File : 2.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','Belvedere Golf & Country Club', reviews_belvedere)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd14076",
   "metadata": {},
   "source": [
    "## 3.Riverview Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14396e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297608-d2432526-Reviews'\n",
    "\n",
    "url_last = 'Riverview_Hotel-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_riverview = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_riverview.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_riverview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ec272ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 3.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','Riverview Hotel', reviews_riverview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572de529",
   "metadata": {},
   "source": [
    "## 4. Treatotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4da6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297608-d1625239-Reviews'\n",
    "\n",
    "url_last = 'Treatotel-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_treatotel = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_treatotel.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_grand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b1810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 296 rows\n",
      "File : 4.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','Treatotel', reviews_treatotel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb714d3b",
   "metadata": {},
   "source": [
    "## 5. BloomSuites | Ahmedabad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8847c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297608-d19893178-Reviews'\n",
    "\n",
    "url_last = 'BloomSuites_Ahmedabad-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_bloom = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_bloom.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_bloom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3480aa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 5.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','BloomSuites | Ahmedabad', reviews_bloom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cc9692",
   "metadata": {},
   "source": [
    "## 6. Hyatt Ahmedabad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ddecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297608-d3607422-Reviews'\n",
    "\n",
    "url_last = 'Hyatt_Ahmedabad-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_hayatt = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_hayatt.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_hayatt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34ba4425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 6.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','Hyatt Ahmedabad', reviews_hayatt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890e1e8",
   "metadata": {},
   "source": [
    "## 7. Novotel Ahmedabad Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43f01a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297608-d5001420-Reviews'\n",
    "\n",
    "url_last = 'Novotel_Ahmedabad_Hotel-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_novo = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_novo.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e401d5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 7.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','Novotel Ahmedabad Hotel', reviews_novo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f4ee80",
   "metadata": {},
   "source": [
    "## 8. Taj Skyline Ahmedabad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b032ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297608-d17384006-Reviews'\n",
    "\n",
    "url_last = 'Belvedere_Golf_Country_Club-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_sky = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sky.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_sky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58b4d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 298 rows\n",
      "File : 8.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','Taj Skyline Ahmedabad', reviews_sky)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7173a",
   "metadata": {},
   "source": [
    "## 9. Fortune Select SG Highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fce27c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297608-d2374352-Reviews'\n",
    "\n",
    "url_last = 'Fortune_Select_SG_Highway-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_fortune = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_fortune.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_fortune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2efa7ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 9.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','Fortune Select SG Highway', reviews_fortune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df06a235",
   "metadata": {},
   "source": [
    "## 10. The Ummed Ahmedabad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "524841c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g297608-d304704-Reviews'\n",
    "\n",
    "url_last = 'The_Ummed_Ahmedabad-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_umm = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_umm.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_umm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "befd8625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 10.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad','Hotels','The Ummed Ahmedabad', reviews_umm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c409e",
   "metadata": {},
   "source": [
    "# Restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c318a9",
   "metadata": {},
   "source": [
    "## 1. Atithi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1efbd977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d2662798-Reviews'\n",
    "\n",
    "url_last = 'Atithi-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_atithi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,320,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_atithi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7576a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 315 rows\n",
      "File : 11.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , 'Atithi' , reviews_atithi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee30202d",
   "metadata": {},
   "source": [
    "## 2. Sankalp Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82468159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d5909789-Reviews'\n",
    "\n",
    "url_last = 'Sankalp_Restaurant-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_sankalp = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_sankalp.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f7b42bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 299 rows\n",
      "File : 12.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , 'Sankalp Restaurant' , reviews_sankalp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f3797a",
   "metadata": {},
   "source": [
    "## 3. Yi Jing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c782aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d24155826-Review'\n",
    "\n",
    "url_last = 'Yi_Jing-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_yi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    #review_div = soup.find_all('div' , class_ = 'prw_rup prw_reviews_text_summary_hsx')\n",
    "    \n",
    "    tags_to_delete = soup.find_all('div' , class_ = 'mgrRspnInline')\n",
    "    \n",
    "    for t in tags_to_delete:\n",
    "        t.decompose()\n",
    "    \n",
    "\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            review_text.span.decompose()\n",
    "            reviews_yi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cb7a491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 299 rows\n",
      "File : 13.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , 'Yi Jing' , reviews_yi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a1946",
   "metadata": {},
   "source": [
    "## 4. The Green House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43511ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d1105413-Reviews'\n",
    "\n",
    "url_last = 'The_Green_House-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_green = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_green.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7ee9b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 14.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , 'The Green House' , reviews_green)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7bbe6d",
   "metadata": {},
   "source": [
    "## 5. 650- The Global Kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c907689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d3732998-Reviews'\n",
    "\n",
    "url_last = '650_The_Global_Kitchen-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_global = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_global.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78b19289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 287 rows\n",
      "File : 15.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , '650- The Global Kitchen' , reviews_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d96d19",
   "metadata": {},
   "source": [
    "## 6. Agashiye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f695f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d786043-Reviews'\n",
    "\n",
    "url_last = 'Agashiye-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_ag = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,320,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_ag.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22fb089b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 315 rows\n",
      "File : 16.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , 'Agashiye' , reviews_ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12d9e2",
   "metadata": {},
   "source": [
    "## 7. Gordhan Thal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68d87855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d1484537-Reviews'\n",
    "\n",
    "url_last = 'Gordhan_Thal-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_thal = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_thal.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "590fbcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 17.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , 'Gordhan Thal' , reviews_thal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d110cc43",
   "metadata": {},
   "source": [
    "## 8. The Great Kabab Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fdbf088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d3906071-Reviews'\n",
    "\n",
    "url_last = 'The_Great_Kabab_Factory-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_fact = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,320,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_fact.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f960ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 315 rows\n",
      "File : 18.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , 'The Great Kabab Factory' , reviews_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851d38f",
   "metadata": {},
   "source": [
    "## 9. Vishalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6529139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d1204344-Reviews'\n",
    "\n",
    "url_last = 'Vishalla-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_vi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_vi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa2be3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 19.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , 'Vishalla' , reviews_vi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96e0e7",
   "metadata": {},
   "source": [
    "## 10. Barbeque Nation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "786615c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g297608-d2042353-Reviews'\n",
    "\n",
    "url_last = 'Barbeque_Nation-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "\n",
    "\n",
    "reviews_bar = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_bar.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66410ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 20.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Restaurants' , 'Barbeque Nation' , reviews_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044295b8",
   "metadata": {},
   "source": [
    "# Things to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61554b",
   "metadata": {},
   "source": [
    "## 1. Hathee Singh Jain Temple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2f63b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297608-d325378-Reviews'\n",
    "\n",
    "url_last = 'Hathee_Singh_Jain_Temple-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "    \n",
    "reviews_hathee = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_hathee.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34eec87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 21.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'Hathee Singh Jain Temple' , reviews_hathee)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de980526",
   "metadata": {},
   "source": [
    "## 2. Vaishnodevi Temple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfb9db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297608-d2665316-Reviews'\n",
    "\n",
    "url_last = 'Vaishnodevi_Temple-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "    \n",
    "reviews_devi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_devi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe460a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 22.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'Vaishnodevi Temple' , reviews_devi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed72a58",
   "metadata": {},
   "source": [
    "## 3. Kankaria Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9d9abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297608-d2284993-Reviews'\n",
    "\n",
    "url_last = 'Kankaria_Lake-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "    \n",
    "reviews_lake = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_lake.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4cf260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 23.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'Kankaria Lake' , reviews_lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955e7531",
   "metadata": {},
   "source": [
    "## 4. Adalaj Step-well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5ac16b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297608-d1219291-Reviews'\n",
    "\n",
    "url_last = 'Adalaj_Step_well-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "    \n",
    "reviews_well = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_well.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "658f90a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 24.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'Adalaj Step-well' , reviews_well)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3c5a89",
   "metadata": {},
   "source": [
    "## 5. Sabarmati Riverfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5b721b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297608-d2501233-Reviews'\n",
    "\n",
    "url_last = 'Sabarmati_Riverfront-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "    \n",
    "reviews_sabar = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sabar.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e67c648d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 25.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'Sabarmati Riverfront' , reviews_sabar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ec5a1",
   "metadata": {},
   "source": [
    "## 6. Manek Chowk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12fec0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297608-d7003701-Reviews'\n",
    "\n",
    "url_last = 'Manek_Chowk-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "    \n",
    "reviews_cho = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_cho.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "368b1b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 26.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'Manek Chowk' , reviews_cho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c1d2d1",
   "metadata": {},
   "source": [
    "## 7. Swaminarayan Akshardham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2a5f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297609-d2693793-Reviews'\n",
    "\n",
    "url_last = 'Swaminarayan_Akshardham-Gandhinagar_Gandhinagar_District_Gujarat.html'\n",
    "    \n",
    "reviews_swami = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_swami.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "616f4928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 27.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'Swaminarayan Akshardham' , reviews_swami)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd620c3f",
   "metadata": {},
   "source": [
    "## 8. Auto World Vintage Car Museum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15029437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297608-d3491731-Reviews'\n",
    "\n",
    "url_last = 'Auto_World_Vintage_Car_Museum-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "    \n",
    "reviews_auto = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_auto.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92b6b37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 28.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'Auto World Vintage Car Museum' , reviews_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3405d",
   "metadata": {},
   "source": [
    "## 9. Sidi Saiyyed Mosque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2852872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297608-d1204349-Reviews'\n",
    "\n",
    "url_last = 'Sidi_Saiyyed_Mosque-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "    \n",
    "reviews_sidi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sidi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "665a67c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 29.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'Sidi Saiyyed Mosque' , reviews_sidi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80a365",
   "metadata": {},
   "source": [
    "## 10. ISKCON Temple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "deb586d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g297608-d2689512-Reviews'\n",
    "\n",
    "url_last = 'ISKCON_Temple-Ahmedabad_Ahmedabad_District_Gujarat.html'\n",
    "    \n",
    "reviews_temp = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_temp.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e99b09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 30.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Ahmedabad' , 'Things' , 'ISKCON Temple' , reviews_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

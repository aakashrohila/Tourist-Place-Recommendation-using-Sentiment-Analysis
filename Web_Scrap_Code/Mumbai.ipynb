{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c8e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2e5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "def writer(city_name, place_to_visit, place_name, reviews):\n",
    "    ''' This method is created to create output excel file with ease '''\n",
    "    global counter\n",
    "    \n",
    "    hotel_dict = {'city_name':city_name, 'place_to_visit': place_to_visit, 'place_name': place_name, 'reviews': reviews}\n",
    "    \n",
    "    df=pd.DataFrame(hotel_dict)\n",
    "    folder_path = f'C:\\Modules\\Major Project\\Web_Scrapping\\\\{city_name}\\\\{place_to_visit}\\\\{counter}.xlsx'\n",
    "    \n",
    "    df.to_excel(folder_path, index=False, header=True)\n",
    "    \n",
    "    print('This files has',len(reviews),'rows')\n",
    "    \n",
    "    print(f'File : {counter}.xlsx written to path')\n",
    "    \n",
    "    counter = counter+1\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2f94f",
   "metadata": {},
   "source": [
    "# MUMBAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df618c56",
   "metadata": {},
   "source": [
    "# Hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384dc580",
   "metadata": {},
   "source": [
    "## 1. The Lalit Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67fb9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d299124-Reviews'\n",
    "\n",
    "url_last = 'The_Lalit_Mumbai-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_lalit = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_lalit.append(review_text.span.text)\n",
    "            \n",
    "#print(reviews_lalit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4027c297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 1.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai','Hotels','The Lalit Hotel', reviews_lalit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c21ed4",
   "metadata": {},
   "source": [
    "## 2. Sahara Star Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9c60e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d678272-Reviews'\n",
    "\n",
    "url_last = 'Sahara_Star_Hotel-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_sahara = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            reviews_sahara.append(review_text.span.text)\n",
    "            #print(review_text.span.text)\n",
    "            #print(len(reviews_sahara))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95dd9494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 2.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai','Hotels','Sahara Star Hotel', reviews_sahara)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80f4e9",
   "metadata": {},
   "source": [
    "## 3. Goldfinch Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ea9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d3774517-Reviews'\n",
    "\n",
    "url_last = 'Goldfinch_Hotel_Mumbai-Mumbai_Maharashtra.html'\n",
    "\n",
    "reviews_goldfinch = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            reviews_goldfinch.append(review_text.span.text)\n",
    "            #print(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917218dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 3.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Hotels' , 'Goldfinch Hotel' , reviews_goldfinch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c2f03",
   "metadata": {},
   "source": [
    "## 4. Ginger Mumbai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f633c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d24872144-Reviews'\n",
    "\n",
    "url_last = 'Ginger_Mumbai_Goregaon-Mumbai_Maharashtra.html'\n",
    "\n",
    "reviews_ginger = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            reviews_ginger.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "615b770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 290 rows\n",
      "File : 4.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Hotels' , 'Ginger Hotel' , reviews_ginger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0e50f",
   "metadata": {},
   "source": [
    "## 5. The Fern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00009df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d11774410-Reviews'\n",
    "\n",
    "url_last = 'The_Fern_Goregaon-Mumbai_Maharashtra.html'\n",
    "\n",
    "reviews_fern = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            reviews_fern.append(review_text.span.text)\n",
    "            #print(review_text.span.text)\n",
    "            #print(len(reviews_lalit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2c2a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 5.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Hotels' , 'The Fern' , reviews_fern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb99dd7",
   "metadata": {},
   "source": [
    "## 6. Trident Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd989c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d472105-Reviews'\n",
    "\n",
    "url_last = 'Trident_Hotel-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_tri = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_tri.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da6eef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 6.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai','Hotels','Trident', reviews_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192cf3cd",
   "metadata": {},
   "source": [
    "## 7. Hotel Residency Fort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85fcff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d304617-Reviews'\n",
    "\n",
    "url_last = 'Hotel_Residency_Fort-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_res = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_res.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f13b9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 7.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai','Hotels','Hotel Residency Fort', reviews_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cdd5ab",
   "metadata": {},
   "source": [
    "## 8. Four Seasons Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5612b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d672189-Reviews'\n",
    "\n",
    "url_last = 'Four_Seasons_Hotel_Mumbai-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_sea = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sea.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbb7db81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 8.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai','Hotels','Four Seasons Hotel', reviews_sea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d10f5b",
   "metadata": {},
   "source": [
    "## 9. Sofitel Mumbai BKC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9701abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d2048980-Reviews'\n",
    "\n",
    "url_last = 'Sofitel_Mumbai_BKC-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_bkc = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_bkc.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6be81b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 9.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai','Hotels','Sofitel Mumbai BKC', reviews_bkc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3b062",
   "metadata": {},
   "source": [
    "## 10. Hotel Sea Princess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d617c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Hotel_Review-g304554-d308382-Reviews'\n",
    "\n",
    "url_last = 'Hotel_Sea_Princess-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_prin = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'fIrGe _T')\n",
    "\n",
    "    for r in review_div:\n",
    "\n",
    "        review_text = r.find('q' , class_ = 'QewHA H4 _a')\n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_prin.append(review_text.span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "024cc070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 10.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai','Hotels','Hotel Sea Princess', reviews_prin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174f462",
   "metadata": {},
   "source": [
    "# Restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054fea0b",
   "metadata": {},
   "source": [
    "## 1. EAST-EAST ASIAN SPICE TRAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbaf6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d10338075-Reviews'\n",
    "\n",
    "url_last = 'EAST_EAST_ASIAN_SPICE_TRAIL-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_east = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "  \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_east.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ac0d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 11.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , 'EAST-EAST ASIAN SPICE TRAIL' , reviews_east)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc3079",
   "metadata": {},
   "source": [
    "## 2. Namak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86d173ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d2034920-Reviews'\n",
    "\n",
    "url_last = 'Namak-Mumbai_Maharashtra.html'\n",
    "\n",
    "reviews_namak = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            reviews_namak.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d93dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 12.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , 'Namak' , reviews_namak)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c34689",
   "metadata": {},
   "source": [
    "## 3. Rasoi Kitchen & Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d61dc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d21511592-Reviews'\n",
    "\n",
    "url_last = 'Rasoi_Kitchen_Bar-Mumbai_Maharashtra.html'\n",
    "\n",
    "reviews_rasoi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           \n",
    "            #print(review_text.text)\n",
    "            #print()\n",
    "            reviews_rasoi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35f28b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 288 rows\n",
      "File : 13.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , 'Rasoi Kitchen & Bar' , reviews_rasoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21696f85",
   "metadata": {},
   "source": [
    "## 4. Mabruk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37b9173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d1008614-Reviews'\n",
    "\n",
    "url_last = 'Mabruk-Mumbai_Maharashtra.html'\n",
    "\n",
    "reviews_mabruk = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            \n",
    "            \n",
    "            #print(review_text.text)\n",
    "            #print()\n",
    "            reviews_mabruk.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5f4130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 14.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , 'Mabruk' , reviews_mabruk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e18c1",
   "metadata": {},
   "source": [
    "## 5. Saptami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed6a9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d8010527-Reviews'\n",
    "\n",
    "url_last = 'Saptami-Mumbai_Maharashtra.html'\n",
    "    \n",
    "reviews_saptami = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "           \n",
    "            #print(review_text.text)\n",
    "            #print()\n",
    "            reviews_saptami.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4bbd16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 15.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , 'Saptami' , reviews_saptami)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab06676",
   "metadata": {},
   "source": [
    "## 6. The Earth Plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f62bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d2034948-Reviews'\n",
    "\n",
    "url_last = 'The_Earth_Plate-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_earth = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_earth.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37bc2fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 16.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , \"The Earth Plate\" , reviews_earth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6725b1",
   "metadata": {},
   "source": [
    "## 7. Peshawri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c22faad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d1014520-Reviews'\n",
    "\n",
    "url_last = 'Peshawri-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_pesh = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_pesh.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2759604e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 17.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , 'Peshawri' , reviews_pesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f8a1a4",
   "metadata": {},
   "source": [
    "## 8. Ark Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66c143b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d5998754-Reviews'\n",
    "\n",
    "url_last = 'Ark_Bar-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_ark = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_ark.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41249856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 18.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , 'Ark Bar' , reviews_ark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bdf4c3",
   "metadata": {},
   "source": [
    "## 9. Hornby's Pavilion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f479d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d786941-Reviews'\n",
    "\n",
    "url_last = 'Hornby_s_Pavilion-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_horn = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_horn.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff6de48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 19.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , \"Hornby's Pavilion\" , reviews_horn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544e1af",
   "metadata": {},
   "source": [
    "## 10. Lake View Cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b6bb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Restaurant_Review-g304554-d1957837-Reviews'\n",
    "\n",
    "url_last = 'Lake_View_Cafe-Mumbai_Maharashtra.html'\n",
    "\n",
    "\n",
    "reviews_lake = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(15,315,15):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = 'ui_column is-9')\n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('p' , class_ = 'partial_entry')\n",
    "        \n",
    "        if review_text != None:\n",
    "            reviews_lake.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b77c896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 20.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Restaurants' , 'Lake View Cafe' , reviews_lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ffb2ea",
   "metadata": {},
   "source": [
    "# Things to do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958fd7fc",
   "metadata": {},
   "source": [
    "## 1. Gateway of India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5c2e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d311667-Reviews'\n",
    "\n",
    "url_last = 'Gateway_of_India-Mumbai_Maharashtra.html'\n",
    "    \n",
    "reviews_gateway = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_gateway.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "518e6ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 21.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Gateway of India' , reviews_mabruk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1eb49",
   "metadata": {},
   "source": [
    "## 2. Juhu Beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "671b8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d321424-Reviews'\n",
    "\n",
    "url_last = 'Juhu_Beach-Mumbai_Maharashtra.html'\n",
    "    \n",
    "reviews_juhu = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_juhu.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6fcdefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 22.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Juhu Beach' , reviews_juhu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6d551",
   "metadata": {},
   "source": [
    "## 3. Marine Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac955e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d321437-Reviews'\n",
    "\n",
    "url_last = 'Marine_Drive-Mumbai_Maharashtra.html'\n",
    "    \n",
    "reviews_marine = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_marine.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e115363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 23.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Marine Drive' , reviews_marine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab04934",
   "metadata": {},
   "source": [
    "## 4. Essel World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b50d50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d321430-Reviews'\n",
    "\n",
    "url_last = 'Essel_World-Mumbai_Maharashtra.html'    \n",
    "    \n",
    "reviews_essel = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_essel.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f82ce10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 24.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Essel World' , reviews_essel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa0498",
   "metadata": {},
   "source": [
    "## 5. Sanjay Gandhi National Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49e49279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d324632-Reviews'\n",
    "\n",
    "url_last = 'Sanjay_Gandhi_National_Park-Mumbai_Maharashtra.html'    \n",
    "    \n",
    "reviews_sanjay = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_sanjay.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b214532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 25.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Sanjay Gandhi National Park' , reviews_sanjay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7ccea",
   "metadata": {},
   "source": [
    "## 6. Shree Siddhivinayak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac056e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d622586-Reviews'\n",
    "\n",
    "url_last = 'Shree_Siddhivinayak-Mumbai_Maharashtra.html'\n",
    "    \n",
    "reviews_siddhi = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_siddhi.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "627cd318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 26.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Shree Siddhivinayak' , reviews_siddhi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c186b5",
   "metadata": {},
   "source": [
    "## 7. Elephanta Caves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be25c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d311664-Reviews'\n",
    "\n",
    "url_last = 'Elephanta_Caves-Mumbai_Maharashtra.html'\n",
    "    \n",
    "reviews_ele = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_ele.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "570f0b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 27.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Elephanta Caves' , reviews_ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f26a6",
   "metadata": {},
   "source": [
    "## 8. Nariman Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c50e82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d3783379-Reviews'\n",
    "\n",
    "url_last = 'Nariman_Point-Mumbai_Maharashtra.html'\n",
    "    \n",
    "reviews_point = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_point.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2197f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 28.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Nariman Point' , reviews_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6181fa",
   "metadata": {},
   "source": [
    "## 9. Water Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bdecef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d324626-Reviews'\n",
    "\n",
    "url_last = 'Water_Kingdom-Mumbai_Maharashtra.html'\n",
    "    \n",
    "reviews_water = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_water.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88394690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 29.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Water Kingdom' , reviews_water)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b70a34",
   "metadata": {},
   "source": [
    "## 10. Chowpatty Beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "413fa408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining user\n",
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "\n",
    "url_first = 'https://www.tripadvisor.in/Attraction_Review-g304554-d311628-Reviews'\n",
    "\n",
    "url_last = 'Chowpatty_Beach-Mumbai_Maharashtra.html'\n",
    "    \n",
    "reviews_beach = []\n",
    "\n",
    "#This loop was necessary to go to next page on trip advisor\n",
    "for x in range(10,310,10):\n",
    "    #This url_mid will change va\n",
    "    url_mid = '-or' + str(x) + '-'\n",
    "    \n",
    "    url = url_first + url_mid + url_last\n",
    "\n",
    "    html_text = requests.get( url , headers = user_agent).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_text , 'html.parser')\n",
    "\n",
    "    review_div = soup.find_all('div' , class_ = '_c')\n",
    "    \n",
    "    \n",
    "    for r in review_div:\n",
    "        \n",
    "        review_text = r.find('div' , class_ = 'biGQs _P pZUbB KxBGd')\n",
    "        \n",
    "        if review_text != None:\n",
    "            #print(review_text.span.text)\n",
    "            #print()\n",
    "            reviews_beach.append(review_text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be8a7440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This files has 300 rows\n",
      "File : 30.xlsx written to path\n"
     ]
    }
   ],
   "source": [
    "writer('Mumbai' , 'Things' , 'Chowpatty Beach' , reviews_beach)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
